% CAPITULO DE INTRODUCCIÓN

\chapter{Introducción}

\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
          Todo comienzo tiene su encanto.
        }
        \begin{flushright}
          \textbf{\textemdash Johann Wolfgang von Goethe}
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}

\bigskip

\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
          The Feynman Problem-Solving Algorithm: \\
          (1) write down the problem; \\
          (2) think very hard; \\
          (3) write down the answer.
        }
        \begin{flushright}
          \textbf{\textemdash Atribuida a Murray Gell-Mann}
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}


\begin{center}{\line(1,0){325}}\end{center}

%--------------------------------------------------------%
  
  El presente Proyecto Fin de Carrera descansa sobre las bases establecidas por otro trabajo
  similar, aunque más modesto, realizado también como Proyecto Final de Carrera de la Ingeniería 
  Técnica en Informática de Sistemas. Éste, \cite{miproyecto}, fue realizado también por 
  quien suscribe, David García Quintas. La dirección también repite, de mano de
  Policarpo Abascal Fuentes y Jorge Jiménez Meana. El haber podido volver a trabajar
  con ellos, sobre el mismo campo en más profundidad así como en otros nuevos, ha sido una suerte,
  y con el presente trabajo aspiramos no sólo a completar el anterior Proyecto, sino también a utilizarlo
  como referente y punto de partida para de esta forma poder desarrollar nuestras ideas sabiéndonos
  conocedores --y creadores-- del total del trabajo.

  Esta base, la biblioteca LibNumth, ha sido modificada en numerosos puntos, llegando a fundirse
  indistinguiblemente con las mejoras y novedades. El resultado es el presente trabajo, bautizado
  como LibMPPLAS. A lo largo de esta introducción se pormenorizarán estas mejoras y novedades.



\section{Motivación}
  Insistir en la implementación de una biblioteca cuyos métodos, desde la distancia, 
  parecen ya cubiertos por numerosas soluciones, tanto libres como comerciales, puede parecer
  superfluo: MatLab, Mathematica, GMP, Pari... muchos de estos paquetes cubren varios aspectos
  de los soportados por esta biblioteca. Sin embargo, exceptuando quizás a Mathematica, no cubren
  simultáneamente todo el espectro de funcionalidades de la biblioteca. O bien su forma de trabajar
  no resulta, a nuestro juicio, tan cómoda\footnote{un ejemplo es el trabajo con cuerpos finitos,
  descritos en la sección \ref{cuerposFinitos}}.


  La característica «estrella» de la biblioteca es el incorporar el tan en boga concepto
  de \emph{paralelismo}. Con la relativamente reciente incorporación de múltiples unidades de ejecución
  --núcleos-- a los procesadores de consumo, se hace necesaria en la industria una revisión drástica de
  los métodos hasta ahora existentes, fundamentalmente orientados a un trabajo secuencial. Se expone
  a continuación una justificación del interés por este campo, así como un pequeño análisis de la situación
  del mismo. Se remite al lector a \cite{landscape} para más detalles.

  \subsection{A rey muerto, rey puesto.} La variante de la manida «Ley» de Moore, la cual mantiene que 
  el rendimiento de los procesadores se duplicaba cada dos años\footnote{varios apuntes: es obvio que 
  se trata de una \emph{observación}, no una «ley» en el sentido científico del término. Sin embargo se
    mantiene este último término por encontrarse ampliamente extendido. Por otra parte, lo dicho
    por Moore en \cite{moore} se refiere no al \emph{rendimiento}, sino al \emph{número de transistores}
  por circuito integrado. El salto a rendimiento se da en base a que a mayor número de transistores, mayor 
    rendimiento. Sin embargo, no tiene por qué cumplirse de forma lineal.}
  no se mantiene por más tiempo. En la figura \ref{fig:perfGraph}
  se muestra la progresión del rendimiento \emph{general} de uniprocesadores de $1978$ hasta $2006$. 
  De $1986$ hasta $2002$, se mantuvo una tendencia de incremento anual del $52 \%$. Sin embargo, del $2002$ al
  $2006$ este incremento se redujo por debajo del $20 \%$, al punto de representar en $2006$ un rendimiento
  tres veces menor del esperado de haberse mantenido la anterior tendencia. Las principales causas se resumen en:
  \begin{description}
  \item[La barrera energética] (\textit{Power wall}) Se ha pasado de considerar al precio de transistores como
  factor limitante, cuando la energía consumida por estos no tenía importancia, a la situación inversa: alimentar
  y sobre todo \emph{refrigerar} centros de cálculo es considerablemente más caro que la inversión en equipos. En muchas
  ocasiones resulta incluso imposible ampliar este tipo de instalaciones no ya por falta de espacio, sino por la imposibilidad
  física de disipar todo el calor residual generado por los equipos.
  \item[La barrera de la memoria] (\textit{Memory wall}) En el pasado, las operaciones aritméticas tales como el producto
  eran lentas comparadas con las instrucciones de lectura/escritura en memoria. Sin embargo, hoy día el cuello
  de botella se encuentra en estas últimas instrucciones de acceso a memoria, siendo las operaciones aritmético-lógicas
  hasta un orden de magnitud más rápidas.
  \item[La barrera a nivel de instrucciones] (\textit{ILP\footnote{Instruction Level Parallelism} wall}) En los últimos 
  años tecnologías tales como la ejecución fuera de orden, la predicción de saltos, la ejecución especulativa de instrucciones, etc.
  han sido las responsables de haber ayudado a que se siguiera cumpliendo la Ley de Moore. Sin embargo, la innovación en estos campos
  parece estar en declive.
  \end{description}

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth,keepaspectratio]{perfGraph} 
    \caption{Rendimiento integer SPEC vs tiempo. (Figura 2 en \cite{landscape})}\label{fig:perfGraph}
  \end{figure}

  La introducción del paralelismo en la computación de propósito general no parece responder a un interés por parte
  de la industria o los consumidores --ya que por otra parte, la computación paralela lleva muchos años siendo
  utilizada en ámbitos especializados--, sino más bien a la única salida que los fabricantes tienen de 
  aspirar a mantenerse dentro de los parámetros de aumento del rendimiento cada cierto tiempo. 
  Algo que reafirma cómo
  la industria se esfuerza por hacer que la observación de Moore se cumpla, y no al revés. Se juega también con el
  hecho de que la formulación original de Moore, referente al número de transistores, se cumple más fácilmente:
  efectivamente, el integrar un mayor número de núcleos en un único encapsulado implica el uso de más transistores. El que
  esto se traduzca en un incremento lineal --o próximo a éste-- dependerá del nivel de paralelización de la arquitectura, software
  del sistema y programas de usuario subyacentes, no sólo del hardware.
 
  Dado que el nuevo método de incremento del rendimiento pasa a ser la explotación del paralelismo en vez de una mayor
  frecuencia de reloj, cualquier mejora obtenida fruto de la paralelización debe tenerse muy en cuenta. 
  En la línea del refrán que encabeza este punto, el «rey» basado en el aumento
  de la frecuencia de reloj o la microarquitectura monoprocesador ha muerto. Se
  da paso presto al nuevo rey del paralelismo. Y al igual que en las situaciones históricas donde realmente se instauraba
  un nuevo monarca, es momento propicio para cambios (\cite{landscape}, conclusiones):
    \begin{quote}
    From a research perspective, however, this is an exciting opportunity. Virtually any
    change can be justified --new programming languages, new instruction set architectures,
    new interconnection protocols, and so on--.
    \end{quote}


  \bigskip

  Un apunte curioso para finalizar: Seth Lloyd analiza en un interesante artículo (\cite{ultimatelimits})
  los límites físicos de la computación, determinados por la velocidad de la luz $c$, la constante
  de gravitación universal $G$ y la constante reducida de Plank $\hbar$ en el marco definitivo de la computación cuántica. 
  Entre otras interesantes conclusiones está como, si se considera un ordenador de $1$ kg. y $1$ litro de volumen, 
  el número máximo --limite \emph{físico}-- de operaciones resulta ser de $5.4258 \times 10^{50}$, con una máxima capacidad
  de almacenamiento de $\approx 10^{31}$ bits --es decir, $1250$ billones de petabtyes.
  A la vista de estas cifras concluye que si la variante de la Ley de Moore relativa al rendimiento se mantuviese, 
  se tardaría «solamente» $250$ años en compensar los $40$ ordenes de magnitud que separan los ordenadores actuales de
  tales máximos teóricos. Parece un cierto indicador de que la Lay de Moore tiene los días contados.
  



  \subsection{Características a destacar}
  No sólo es el uso del paralelismo lo que caracteriza a esta biblioteca. Varias tecnologías y enfoques
  novedosos han sido aplicados también: comprobaciones en tiempo de compilación, verificación de la coherencia
  algebraica de los tipos, el reciente paradigma de la «programación orientada a aspectos» (AOP), \textit{mock
    objects} que suplantan funcionalidades cuando éstas no se encuentran disponibles para homogeneizar el código,
   patrones de diseño tales como los \textit{mix-ins}, etc. Los pormenores de las tecnologías utilizadas se exponen
   en el capítulo \ref{chap:tecnologias}.
   Aún con el afán de investigar enfoques útiles a la vez que originales, incluso en los programas de ejemplo desarrollados
   se han utilizado técnicas como la autoescritura e interpretación en tiempo de ejecución de código y computación distribuida
   mediante XML-RPC. Puntualizando de forma resumida:


    \begin{itemize}
      \item Comprobaciones estáticas en tiempo de compilación. Utilizadas, por ejemplo, para asegurar
          la coherencia matemática en los tipos de datos. Ver \ref{tech:staticasserts}.
      \item Utilización de programación orientada a aspectos para la implementación de conceptos «transversales» 
            (\textit{cross-cutting concepts}). Se descifra el significado de una frase tan críptica como la anterior en 
            \ref{tech:aop}.
      \item Extensa utilización de programación genérica. Por ejemplo, en la implementación de los tipos matriz 
            --sección \ref{impl:matrices}-- y polinomio --sección \ref{impl:polinomios}--.
      \item Generación dinámica de código --sección \ref{desc:dynamic}--.
      \item Excepciones propias integradas dentro de la jerarquía estándar de C++ para el tratamiento de errores,
            con la incorporación de mecanismos para facilitar la identificación del lanzador de las mismas --sección \ref{controlDeErrores}--.
      \item Repositorio de implementaciones de métodos posibilitando que el usuario aporte su propia implementación
            de los mismos --sección \ref{basico:nuevoRepdeFuncs}--.
      \item Uso de tecnologías SIMD si éstas están disponibles --sección \ref{basico:cpusimd}--.
      \item Soporte de múltiples arquitecturas, incluyendo de $64$ bits --sección \ref{impl:64bits}--.
      \item Utilización del API OpenMP para la paralelización --capítulo \ref{chap:par}--.
      \item Utilización del API pthreads para garantizar la correcta ejecución de la biblioteca en programas concurrentes,
      no necesariamente paralelos.
    \end{itemize}

   Resumiendo: no es sólo el interés por desarrollar un abanico relativamente amplio de métodos con los cuales resulte 
   cómodo trabajar --cuyo rendimiento no sea puntero pero sí competitivo--, sino también explorar nuevas técnicas y su aplicación
   práctica a problemas concretos. Es con esta experimentación original mediante la cual modestamente se espera 
   contribuir al eventual progreso de la computación científica.  

    Asimismo, se soportan los siguientes tipos de entidades, descritas con más detalle en el capítulo \ref{chap:tipos}:
      \begin{itemize}
        \item Números enteros, $\mathbb{Z}$
        \begin{itemize}
          \item Enteros de longitud arbitraria.
          \item Aritmética general.
          \item Generación de números aleatorios.
          \item Orientadas hacia la Teoría de Números.
          \begin{itemize}
            \item Símbolos para Residuos Cuadráticos
            (Legendre-Jacobi-Kronecker).
            \item Rutinas para el cálculo del Máximo Común Divisor (GCD).
            \item Rutinas para el cálculo del Mínimo Común Múltiplo (LCM).
            \item Pruebas de primalidad.
            \item Generación de primos.
            \item Algoritmos de factorización.
            \item Algoritmos de potenciación.
            \item Teorema Chino de los Restos (CRT).
          \end{itemize}
          \item Aritmética modular.
          \begin{itemize}
            \item $\mathbb{Z}_n$: enteros modulares con módulo arbitrario.
            \item $\mathbb{Z}_p$: enteros modulares con módulo primo.
            \item $\mathbb{Z}M_n$: los llamados enteros modulares de Montgomery, desarrollo
            original para la biblioteca.
            \item Potenciación modular.
            \item Métodos especiales de reducción. 
            \item Cálculo de inversas.
          \end{itemize}
        \end{itemize}
        
        \item Conjunto $\mathbb{R}$
        \begin{itemize}
            \item Operaciones aritméticas habituales sobre $\mathbb{R}$.
            \item Precisión (decimal) arbitraria.
            \item Técnicas para un redondeo correcto.
            \item Soporte de notación científica.
            \item Algoritmos de potenciación.
            \item Cálculo de funciones trascendentes: exponencial,
                  logaritmo, funciones trigonométricas, cálculo de la constante $\pi$.
            \item Extracción de la raíz cuadrada.
        \end{itemize}
 
        \item Polinomios.
        \begin{itemize}
          \item Cálculo del máximo común divisor.
          \item Generación de polinomios irreducibles.
          \item Pruebas de irreducibilidad.
          \item Pruebas del carácter primitivo del polinomio.
          \begin{itemize}
            \item Sobre $\mathbb{Z}$.
            \item Sobre $\mathbb{R}$.
            \item Sobre $\mathbb{Z}_n$.
            \item Sobre $\mathbb{Z}_p$.
            \item En general, sobre cualquier tipo implementando \texttt{mpplas::Ring}.
          \end{itemize}
        \end{itemize}

        \item Cuerpos finitos/extensiones de cuerpos $\GF(p^n)$.
        \begin{itemize}
          \item Operaciones aritméticas habituales.
          \item Cálculo del máximo común divisor.
          \item Cálculo de los coeficientes de Bézout.
          \item Generación de polinomios irreducibles.
          \item Generación de polinomios primitivos.
        \end{itemize}

        \item Matrices.
        \begin{itemize}
          \item Cálculo del determinante, tanto sobre matrices sobre un cuerpo como sobre un anillo.
          \item Resolución de sistemas de ecuaciones.
          \item Cálculo de la inversa.
          \item Transposición.
          \begin{itemize}
            \item Sobre $\mathbb{Z}$.
            \item Sobre $\mathbb{R}$.
            \item Sobre $\mathbb{Z}_n$.
            \item Sobre elementos de un cuerpo finito $\GF{(p^n)}$.
            \item En general, sobre cualquier tipo implementando \texttt{mpplas::Group}.
          \end{itemize}
        \end{itemize}
      \end{itemize}


\section{El sistema de desarrollo}\label{sistemaDeDesarrollo}
  \subsection{Sistemas hardware}\label{sistemaHard}
  \begin{description}
    \item[Intel Core 2 Duo E6750 CPU] 
      Sistema multinúcleo en el que se han ejecutado las pruebas en paralelo. 
      Esta CPU posee $128$ kB de memoria caché de primer nivel y $4096$ kB de segundo nivel. Sin caché de tercer nivel.
      Cuenta con $2$ gigabytes de memoria convencional. Su sistema operativo ha sido Scientific Linux 5.0.
    \item[Intel Pentium M Banias B1 CPU] 
      Sistema monoprocesador y principal plataforma de desarrollo. 
      $32$ kB de caché de primer nivel y $1024$ kB de segundo nivel. Sin caché de tercer nivel. Cuenta con
      $1.2$ gigabytes de memoria convencional. Su sistema operativo ha sido Ubuntu 7.04.
  \end{description}

  \subsection{Sistemas software}
  \begin{description}
    \item[Sistema operativo Linux.]
      En su versión 2.6.x. Ha sido el sistema operativo
      principal en el desarrollo. Los distintos programas y versiones
      de bibliotecas fundamentales del sistema han sido:
      \begin{description}
        \item[Bibliotecas del sistema.]  Implementación GNU de la biblioteca de C 
          (incluye POSIX Threads), versión 2.5. 
        \item[Compiladores.] Nombres y versiones de los compiladores soportados.
        \begin{description}
          \item[GCC] Compilador GNU Compiler Collection, en dos diferentes variedades: con soporte
          OpenMP (versión especial de RedHat 4.1.1 con el soporte OpenMP de la versión 4.2) y sin él
          (versión oficial 4.1.2). 
          \item[Intel Compiler] En su versión 9.1. Soporta OpenMP.
        \end{description}
        \item[Documentación.] Herramientas utilizadas para la elaboración de los diferentes tipos de documentación.
          \begin{description}
            \item[\LaTeXe{}.] Versión 3.141592\footnote{un inciso curioso: las versiones de \TeX{} se numeran de
            forma convergente al valor de $\pi$}, para la creación de la presente memoria.
            \item[Beamer.] Versión 3.06, para la creación de las transparencias a ser utilizadas durante
            la defensa.
            \item[Doxygen.] Versión 1.5.1, para el procesador de la documentación embebida en los comentarios del código.
            \item[Gnuplot.] Versión 4.2, para la creación de las gráficas que acompañan a la memoria.
            \item[Dia.] Versión 0.96.1, para la creación de los diagramas presentes en la documentación.
          \end{description}
        \item[Herramientas de desarrollo.] Utilizadas durante el desarrollo de la biblioteca, su batería
        de pruebas y sus aplicaciones de ejemplo.
        \begin{description}
          \item[VIM.] Versión 7.0, para la escritura del código y la documentación. 
          No se ha utilizado ningún tipo de entorno para la creación del código.
          \item[Valgrind.] Para el perfilado de los métodos y verificar la no existencia de fugas de memoria.
          \item[Subversion.] Versión 1.4.3, para el control de versiones.
          \item[SCons.] Versión 0.96.93, para el control del proceso de compilación.
        \end{description}
        \item[Software adicional.] Paquetes software adicionales utilizados durante el desarrollo.
          \begin{description}
            \item[Python.] Versión 2.5, para la implementación del cliente de MPPLab y la creación
            de código C++ en tiempo de compilación.
            \item[AspectC++.] Versión 1.0pre3, para la integración de mecanismos de AOP.
            \item[QtUnit.] Versión 0.9.8, para las baterías de pruebas.
          \end{description}
      \end{description}
      
    \item[Sistema operativo Windows.] Dado que el uso de este sistema se reduce a la ejecución
    del cliente de MPPLab, será valida toda versión del mismo capaz de ejecutar el intérprete de Python.
    \end{description}


    \subsubsection{Software libre}
      Todos el software anteriormente señalado --a excepción de Microsoft Windows y Gnuplot-- es \emph{libre}
      en el sentido definido por la Free Software Fundation\footnote{\url{http://www.fsf.org}}. 
      La utilización única y exclusivamente de software libre durante el desarrollo no ha sido intencionada. 
      Simplemente las herramientas más adecuadas han resultado ser libres. 
      En el caso
      particular de Gnuplot, pese a lo engañoso de su nombre, se trata solamente de software \emph{gratuito}, 
      no libre. Microsoft Windows, aunque pudiera no parecerlo, no es ni lo uno ni lo otro. 

      Las ventajas del uso de software libre son principalmente la libertad, valga la redundancia, que otorga el hecho
      de poder ser utilizado al antojo, su disponibilidad en numerosos sistemas, la enorme comunidad que 
      rodea a este tipo de proyectos, etc. No menos importante resulta que su código fuente esté disponible 
      para su estudio. Esto, que pudiera ser tachado de banal, no lo es en absoluto: ya en la memoria 
      correspondiente a LibNumth (\cite{miproyecto}) se apunta cómo se estudió el código de proyectos como 
      NTL\footnote{\url{http://www.shoup.net/ntl/}}, Pari \footnote{\url{http://pari.math.u-bordeaux.fr/}} 
      o GMP \footnote{\url{http://gmplib.org/}}. 
      
      Por último, pero no por ello menos importante, no debe descuidarse la vertiente filosófica de que,
      si a lo que se aspira es a la creación de conocimiento en pos de la Ciencia, éste ha de ser libre,
      por la propia naturaleza de la Ciencia. De hecho, en un reciente artículo, \cite{opensourcemathsw}, 
      se analiza la problemática derivada del uso de software matemático de carácter propietario y sus repercusiones.
      En este artículo se cita a su vez a Joachim Neubüser:
      \begin{quote}
      (...) with this situation [el uso de software matemático de carácter propietario] 
      two of the most basic rules of conduct in mathematics 
      are violated: In mathematics information is passed on free of charge and everything 
      is laid open for checking.
      \end{quote}
      Si, además, la defensa de la utilización de métodos propietarios se realiza 
      en el marco de métodos de seguridad informática, se estaría incurriendo
      en lo conocido como «seguridad a través de la ocultación» --\textit{security through obscurity}--,
      ámpliamente analizado durante los últimos $30$ años, véase \cite{obscurity}.

      Si la no divulgación de resultados y/o métodos tiene un lugar, éste no puede ser el ámbito científico.
      

\section{Instalación del software de soporte}
  Se depende de algunos paquetes software adicionales, enumerados a continuación junto con indicaciones
  para su obtención e instalación. 
  \subsection{Python}
    Es utilizado por el sistema de compilado SCons y el cliente de MPPLab.
    Su instalación resulta trivial, tanto en sistemas Unix como Windows, siguiendo los pasos indicados en su
    página \textit{web}, desde donde también es posible descargarlo: \url{http://www.python.org/download/}.
  \subsection{SCons}
    Herramienta utilizada para la gestión del proceso de compilación, descrita en la sección \ref{tech:scons}. 
    Dado que la compilación de la biblioteca sólo está soportada en entornos Unix, la forma más sencilla
    de instalar SCons en estos sistemas es utilizar el sistema de paquetes de la variedad de Unix en cuestión.
    En cualquier caso, en las raras ocasiones en las que no existe soporte para SCons por parte del sistema
    de paquetes, su instalación resulta sencilla y tan sólo requiere, de nuevo, de la presencia de Python 
    en el sistema. Se encuentra disponible en \url{http://www.scons.org/download.php}.
  \subsection{AspectC++} Metacompilador utilizado para dotar a C++ de mecanismos de programación orientada
  a aspectos. Su forma más conveniente de distribución es en forma de binarios precompilados, por lo que 
  no es necesario un proceso de instalación propiamente dicho. Es posible descargarlos de \url{http://www.aspectc.org}.
  \subsection{QTUnit} Implementación del concepto de pruebas unitarias --sección \ref{testunits}--, se encuentra
  disponible en \url{http://www.uwyn.com/projects/qtunit/download.html}.
  \subsection{libpari} Extensa biblioteca para el trabajo con Teoría de Números, Álgebra y Cálculo Numérico, se ha 
  utilizado a modo de «oráculo» en las baterías de pruebas --sección \ref{tech:oraculo}--.
