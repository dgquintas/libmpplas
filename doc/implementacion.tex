% CAPITULO IMPLEMENTACION 

\chapter{Implementación de algoritmos
básicos}\label{implementacionAlgoritmosBasicos}

\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
        Most security failures [in cryptography] are due to failures in 
        implementation, not failure in algorithms or protocols.
        }
        \begin{flushright}
          \textbf{\textemdash Agencia Nacional de Seguridad Estadounidense (NSA)}
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}

\bigskip

\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
        The vast majority of security failures occur at the level 
        of implementation detail.
        }
        \begin{flushright}
          \textbf{\textemdash Ross Anderson}
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}

\bigskip

\begin{center}{\line(1,0){325}}\end{center}

%--------------------------------------------------------%
\section{Introducción}
  La correcta implementación de estos métodos es fundamental, por ser
  los pilares de todo el trabajo de la librería. Pero no sólo ha de
  cuidarse su corrección sino también el que realicen su tarea con una
  velocidad lo más cercana a lo óptimo posible. También al plantear
  el algoritmo ha de tenerse esto en cuenta, ya que en el paso de la
  especificación a la implementación real se han de tomar decisiones
  importantes, y aún hay cabida a mejoras muchas veces sustanciales.

  
\section{La CPU básica}\label{implementacionCpuBasica}
    Como se describe en \ref{elProcesadorVirtual}, es necesario 
    contar con un conjunto de operaciones básicas (descritas en 
    \cite{cohen}\footnote{pág. 4})
    que operen sobre el tipo de dato básico considerado: \emph{Cifra}
    (recordando, números en base $B$ con los que la máquina trabaja 
    internamente de forma óptima). Se ha de contar al menos con:
    \begin{itemize}
      \item Suma o resta de dos enteros básicos, resultando un entero 
        básico y un acarreo.
      \item Multiplicación de dos enteros básicos, resultando un
      \emph{doble} entero básico. 
      \item División de un \emph{doble} entero básico por un entero
      básico, resultando dos enteros básicos: el cociente y el
      resto.
    \end{itemize}
    El término \emph{doble} se refiere a que se obtiene un
    número en base $B^2$. Para el manejo nativo de estos números, se
    manejará la parte alta y la baja por separado. Además de estos
    mínimos, se consideran también otras operaciones incluidas por su
    utilidad. Se verán en la siguiente descripción.
 
    Toda variable citada será del tipo \emph{Cifra} y por tanto tendrá 
    una longitud básica igual a la de la base $B$ considerada.
    A dicha longitud, expresada en
    bits, se la denominará \index{BITS\_EN\_CIFRA}{\texttt{BITS\_EN\_CIFRA}} 
		---en esta sección \texttt{BEC}.

    Las operaciones de suma, resta y multiplicación se presentan en
    dos variantes, con el fin de facilitar la gestión de los acarreos.
    Estas variantes son \texttt{Addx}, \texttt{Subx} y
    \texttt{Addmul}.
    
    \begin{description}
      \item[\texttt{resto}] puede almacenar, en función de la operación, lo
        siguiente:
        \begin{itemize}
          \item Parte alta del resultado de una multiplicación.
          \item Parte alta del dividendo previamente a la división.
          \item Resto de una división tras la misma.
          \item Parte baja de una cifra tras un desplazamiento hacia la izquierda.
          \item Parte alta de una cifra tras un desplazamiento hacia la derecha.
        \end{itemize}
      \item[\texttt{overflow}] contendrá el acarreo de las operaciones de
        suma y resta. Tomará por tanto únicamente valores de $1$ ó
        $0$\footnote{
        Independientemente de la base, el acarreo será siempre $0$ ó $1$:
        $(B-1) + (B-1) = 2B - 2$, $[\frac{2B - 2}{B}] = [2 - \frac{2}{B}]$.
        Pero ya que $ [\frac{2}{B}] = 1 \quad \forall B \geq 2$, el acarreo
        será siempre, como mucho, de una posición.
        Asimismo, es claro que $(B-k) + (B-l) < B \Leftrightarrow B <
        k + l$ y el acarreo sería por tanto $0$.
      }.

    \item[\texttt{c = Add(a,b)}] suma $a$ y $b$ dejando los BEC de menor peso
			en $c$. Si se produce desbordamiento, se pone	$overflow = 1$
			
			$a + b = c + overflow \times B$.

    \item[\texttt{c = Addx(a,b)}] añade a la suma de $a$ y $b$ el contenido
			de $overflow$, dejando los BEC de menor peso en $c$. Si se
			produce desbordamiento, se activa la marca de $overflow$.
			
			$a + b + overflow_1 = c + overflow_2 \times B$.
			
    \item[\texttt{c = Sub(a,b)}] resta $a$ y $b$ dejando los BEC resultado en $c$.
			Si se produce desbordamiento, se activa la marca de	$overflow$
			\footnote{
				Esto en realidad sería un ``underflow''. El uso 
				de $overflow$ en su lugar es un abuso del lenguaje.
			}.
			
			$a - b = c - overflow \times B$.
			
    \item[\texttt{c = Subx(a,b)}] resta $overflow$ a la diferencia de $a$ y $b$ 
			dejando los BEC resultado en $c$.
			Si se produce desbordamiento, se activa la marca de	$overflow$.
			
			$a - b - overflow_1 = c - overflow_2 \times B$.
			
    \item[\texttt{c = Mul(a,b)}] multiplica $a$ por $b$, devolviendo los
			BEC de la parte baja del resultado y almacenando en $resto$ 
			los BEC de la parte	alta. 
			
			$a \times b = $resto$ \times B + c$ .
			
			
    \item[\texttt{c = Addmul(a,b)}] suma al producto de $a$ por $b$ el
      contenido de $resto$, devolviendo los BEC de la parte baja del
      resultado y almacenando en $resto$ la parte alta.

      $ab + resto_1 = c + resto_2 \times B$.

      
    \item[\texttt{c = Div(a,b)}] devuelve en $c$ el cociente entero de la 
			división de $resto \times B + a$ entre $b$. Se almacena el resto 
			de la	división en $resto$. Se asume\footnote{
				En general, consideremos $u = (u_n u_{n-1} \ldots u_1 u_0)$ y $v =
				(v_{n-1} \ldots v_1 v_0)$ dos números de $(n+1)$ y $n$
				cifras respectivamente. Para que el cociente pueda
				representarse como un único número en base $B$, ha de
				cumplirse que $0 \leq [\frac{u}{v}] < B \quad \Leftrightarrow
				\quad [\frac{u}{B}] < v \quad \Leftrightarrow (u_n u_{n-1}
				\ldots u_1) < (v_{n-1} \ldots v_1 v_0) $. Si lo
				particularizamos para $n=1$, tenemos que la cifra más
				significativa del dividendo ha de ser estrictamente menor que
				la única cifra del divisor para que el cociente sea
				representable en base $B$.
			} que inicialmente $b > resto$.
			
			$resto_1 \cdot B + a = b \cdot c + resto_2$. 

    \item[\texttt{c = Shiftl(a,b)}] devuelve en $c$ los BEC de la parte
			baja del producto $2^b \cdot a$ y almacena en $resto$ los BEC de
			la parte alta. Se asume que $0 \leq b < \lg_2 B$. 
			
			$2^b \cdot a = resto \cdot B + c$                       
	
    \item[\texttt{c = Shiftlr(a,b)}] devuelve en $c$ los BEC de la parte
			alta de $a << BEC$ entre $2^b$ y almacena en $resto$ los BEC de
			la parte baja.\footnote{
        Se desplaza inicialmente $a$ hacia la izquierda un
        número de posiciones igual a la base para evitar perder la
        información "por la derecha".
      } Se asume que $0 \leq b < \lg_2 B$.

      $\frac{a \cdot B}{2^b} = c \cdot B + resto$

    \item[\texttt{c = Bfffo(a)}] devuelve en $c$ el número de ceros
      binarios a la izquierda del primer uno. Esto es, el número de
      posiciones que habría que desplazar el número binario hacia la
      izquierda para que su cifra más significativa fuera $1$.\\
      Si consideramos $B = 2^m$, 

      $c \in \mathbb{Z}\ / \  \frac{B}{2} \leq 2^c a < B$ o
      de forma equivalente 
      \begin{math}
      c = \left\{ 
        \begin{array}{ll}
          \lceil lg_2{\frac{B}{2a}} \rceil & \textrm{si $a \neq 0$}\\
          m                                & \textrm{si $a = 0$}
        \end{array}
        \right.
      \end{math}
		\end{description}

    Como para cada arquitectura hardware soportada ha de existir una
    implementación diferente, la clase \texttt{vCPUBasica< Arch >} es
    una plantilla que, correctamente instanciada en tiempo de
    compilación a uno de los valores de la estructura \texttt{Arch},
    implementa los métodos deseados en cada caso. 

    \subsection{Perfilado}\label{perfilado}
      Mención especial merecen las versiones de
      \index{perfilado}{perfilado} de esta CPU básica. Las versiones de
      la CPU básica que lo soporten tendrán \texttt{Prof} como coletilla
      al nombre de la arquitectura. Tanto para ver las arquitecturas
      soportadas como las que ofrecen soporte de perfilado, véase la
      estructura \texttt{Arch} en el tomo del código fuente.

      Lo que este particular mecanismo mide son fundamentalmente dos
      cosas:
      \begin{enumerate}
        \item El número de veces que se invoca cada operación de la
          CPU básica.
        \item El tiempo consumido con precisión de centésimas de
          segundo.
      \end{enumerate}
      El control de los intervalos de medición se realiza mediante
      la clase \texttt{Perfil}, y los valores de los anteriores datos 
      serán los medidos entre las llamas a los métodos
      \texttt{iniciar()} y \texttt{finalizar()} de esta clase. Además,
      se proporciona otro método \texttt{acumular()} con el fin de que
      los contadores, que recordemos trabajan a nivel de la CPU
      básica, sean vaciados sobre un entero de longitud arbitraria si
      el intervalo de medición es tan largo que pudieran desbordarse.
      Para información sobre los métodos de obtención de datos y
      demás, consultar el tomo del código.
      

  \section{Algoritmos sobre $\mathbb{Z}$}\label{algoritmosSobreZ}
  Los algoritmos presentados en esta sección se corresponden
  fundamentalmente con la denominada CPU Vectorial
  (\ref{estructuraGeneralDeLaLiberia}). Sin embargo, resulta más
  cómodo definir los métodos en general, por lo que en esta sección ha
  de entenderse que se realiza asimismo un tratamiento del signo del
  número en las operaciones, como se efectúa en la implementación de
  la capa superior de la CPU Vectorial. Véase
  \ref{estructuraGeneralDeLaLiberia} para más detalles.

  
  \subsection{Representación}\label{representacionZ}
  Se busca una forma de representar los enteros de manera que las
  operaciones puedan implementarse de la forma más natural posible y,
  claro está, con una eficiencia óptima. No hace falta irse muy lejos
  para encontrar, en la propia forma de escribir un entero para una
  base determinada, lo que se está buscando. Observemos lo siguiente:
  \begin{observacion}
    Si $B \geq 2$ es un entero, cualquier numero $a \in \mathbb{Z}$
    puede ser representado de forma única como 
    \begin{equation}\label{eq:repVector} 
      a = a_n B^n + a_{n-1} B^{n-1} + \ldots + a_1 B + a_0 
    \end{equation}
    donde $a_i$ es un entero, con $0 \leq a_i < B$ para $ 0 \leq i
    \leq n$ con $a_n \neq 0$.
  \end{observacion}
  Basándonos en esto, parece adecuado almacenar un número en base $B$ como
  un vector de valores menores estrictamente que $B$,
  representando los coeficientes del polinomio que identifica a todo
  entero en dicha base.
  \begin{center}\label{vector_repr}
    \begin{tabular}{|c|c|c|c|c|}
      \hline
        $a_n$ & $a_{n-1}$ & $\ldots$ & $a_1$ & $a_0$  \\
      \hline
    \end{tabular}
    \\*
    \begin{tabular}{@{}lcr@{}}
			Más peso & & Menos peso 
		\end{tabular}	
  \end{center}

  Nótese la organización de los coeficientes. A mayor índice, mayor
  peso. En algunos textos como \cite{knuth2} se utiliza el convenio
  inverso. En cualquier caso, esta elección es poco importante.
  Señalar únicamente el hecho de que presenta algunas ventajas como la
  señalada en \cite{riesel}\footnote{pág. 334}, que se apoya 
  en lo siguiente:
  \begin{observacion}
    Sea $N_B = a_n B^n + a_{n-1} B^{n-1} + \ldots + a_1 B + a_0$ y $d
    \in \mathbb{Z}$ tal que $d | B$. Entonces
    se verifica 
    \[ N_B \equiv a_0 \pmod{d} \]
  \end{observacion}
%  \begin{demostracion}
%    Dado que $d | B$, $[\frac{N_B}{d}] = k_n + k_{n-1} + \ldots + k_1$
%    con $k_i \in \mathbb{Z}, 1 \leq i \leq n$. El resto de dicha
%    división será aquel termino que no se encontraba multiplicando a
%    la base, es decir, $a_0$. Es claro que puede darse el caso de que 
%    $a_0$ fuera múltiplo de $d$. Por tanto, $N_B \bmod{d} = a_0 \bmod{d}$.
%  \end{demostracion}
  Por tanto, una operación tan habitual como la reducción en módulo
  puede acelerarse de manera considerable teniendo en cuenta el
  anterior teorema. La mejora en lo referente a la ordenación de los
  coeficientes es que no hemos de preguntar por el tamaño del vector
  para aplicarlo, cosa que sí deberíamos hacer de considerar como
  coeficiente menos significativo aquél de mayor índice.

  \paragraph{Los enteros negativos} se representarán simplemente 
    mediante el número ``en positivo'', pero marcando en la estructura
    de datos correspondiente el hecho de que se trata de un número
    negativo. Esta marca será tenida en cuenta, naturalmente, a la 
    hora de operar. En cualquier caso, \emph{no} se utilizarán métodos
    del tipo complemento a dos ni similares.

    \subsubsection{La estructura \texttt{MiVec<T>}}
      Para la implementación concreta de la estructura que almacena
      los $a_i$ de la ecuación (\ref{eq:repVector}) se incorpora 
      \texttt{MiVec<T>}. ¿Por qué utilizar esta estructura cuando ya
      C++ satisface con STL prácticamente cualquier necesidad en este
      sentido? En primer lugar, para aportar un poco más de
      flexibilidad. Pudiera ser que esta forma de representar los
      enteros se cambiase y, de haber dependido por ejemplo del
      contenedor \texttt{vector<T>} de la STL, tendría que realizarse
      una reescritura prácticamente línea por línea a lo largo de toda
      la librería. Proporcionando una estructura propia se goza de,
      digamos, un mayor grado de autonomía o control. En segundo
      lugar, y en relación con lo anterior, por la necesidad de contar
      con un objeto que brinde algunas características especiales
      requeridas por la librería, en concreto el lanzamiento de
      excepciones (véase \ref{controlDeErrores})
      en accesos inválidos. Éste es uno de los errores más
      frecuentes y de más difícil detección en la programación con
      C/C++, derivando frecuentemente en accesos inválidos que pueden
      revelarse en fallos del programa no necesariamente síncronos con
      el acceso inválido. Por ello se tomó la decisión de, a costa de
      una pequeña constante en el rendimiento, realizar comprobaciones 
      en cada acceso a la estructura. Pero siempre podría desactivarse esta
      característica sin más que reescribir el método
      \texttt{operator[]} del objeto, aunque se desaconseja en pro de
      un óptimo funcionamiento de la detección de errores.
  
  \subsection{Operaciones}
 		De las operaciones en datos básicos descritas en 
		\ref{implementacionCpuBasica}, podemos construir las generalizaciones
    a múltiple precisión (\cite{knuth2}\footnote{pág. 250}):
    \begin{itemize}
      \item Suma o resta de enteros de $n$ cifras, resultando en un
      entero de $n$ cifras y un acarreo. 
    \item Multiplicación de un entero de $n$ cifras por un entero de
      $m$ cifras, resultando un entero de $(m+n)$ cifras.
      \item División de un entero de $(m+n)$ cifras por un entero de
      $n$ cifras, resultando en un cociente de $(m+1)$ cifras y un
      resto de $n$ cifras.
    \end{itemize}
  Además del tipo \index{Cifra}{\emph{Cifra}}, definido en \ref{elProcesadorVirtual},
  se considera también \index{CifraSigno}{\emph{CifraSigno}}
  como un número $-2^{B-1} \leq CifraSigno < 2^{B-1}$, es decir, del mismo
  tamaño que \emph{Cifra} pero con uno de sus bits utilizados en
  representar el signo.
  
  \subsubsection{Suma}\label{suma}
    El más simple de los métodos de la sección, se muestra en el
    algoritmo \ref{alg:suma}.

    \begin{algorithm}
      \caption{Suma en $\mathbb{Z}^+$}\label{alg:suma}
      \begin{algorithmic}[1]
        \Procedure{Suma}{entero $a=(a_n a_{n-1} \cdots a_1)_B$, 
                         entero $b=(b_n b_{n-1} \cdots b_1)_B$}
        \State $acarreo \gets 0$
        \For{$i=1$ hasta $i=n$}
          \State $c_i \gets (a_i + b_i + acarreo) \bmod B$
          \State $acarreo \gets \lfloor(a_i + b_i + acarreo) / B\rfloor$
        \EndFor
        \If{$acarreo = 1$}
          \State $c_{n+1} \gets 1$
        \EndIf
        \State \textbf{devolver} $c$
        \EndProcedure
      \end{algorithmic}
    \end{algorithm}

    Ejemplo de la utilidad del uso de la CPU Básica tal y como se ha
    definido es el hecho de que el bucle principal del anterior 
    algoritmo \ref{alg:suma} se escribe mediante las operaciones 
    de dicha CPU con únicamente la instrucción \texttt{Addx},
    realizándose la gestión de los acarreos de forma transparente.
    Véase el tomo del código fuente (función \verb|sumaMP| para más detalles). 

 
    Es claro ver que el número de operaciones básicas ejecutadas para
    la suma de dos números de $n$ Cifras es $O(n)$, y no parece haber
    forma de rebajar esta cota asintótica.
    
  \subsubsection{Resta}\label{resta}
    El segundo de los métodos fundamentales es tan sólo ligeramente
    más complejo que la suma. Se representa en el algoritmo \ref{alg:resta}.
    Atención al hecho de que el minuendo ha de ser mayor o igual que
    el sustraendo, ya que estos algoritmos trabajan en $\mathbb{Z}_0$.
    Como ya se ha indicado, el tratamiento de signos se realiza en una
    capa superior.

    \begin{algorithm}
      \caption{Resta en $\mathbb{Z}^+$}\label{alg:resta}
      \begin{algorithmic}[1]
        \Procedure{Resta}{entero $a=(a_n a_{n-1} \cdots a_1)_B$, 
                         entero $b=(b_n b_{n-1} \cdots b_1)_B$}
        \Require $a \geq b$
        \State $acarreo \gets 0$
        \For{$i=1$ hasta $i=n$}
          \State $c_i \gets (a_i - b_i + acarreo) \bmod B$
          \State $acarreo \gets \lfloor(a_i - b_i + acarreo) / B\rfloor$
        \EndFor
        \If{$acarreo = 1$}
          \State $c_{n+1} \gets 1$
        \EndIf
        \Ensure $acarreo =0$, ya que de otro modo, se estaría en
        contradicción con el requisito inicial de $a \geq b$.
        \State \textbf{devolver} $c$
        \EndProcedure
      \end{algorithmic}
    \end{algorithm}

    De nuevo, y esta vez con incluso más razón, el uso de la CPU Básica 
    libra de la gestión manual a este nivel de los acarreos, que en
    este caso son más complicados de manejar: sin más que utilizar la
    instrucción \texttt{Subx}, todo se realiza de forma transparente
    siguiendo la definición de la instrucción como fue dada en
    \ref{implementacionCpuBasica}. Véase el tomo del código fuente (función
    \verb|restaMP| para más detalles). 
 
    El número de operaciones básicas ejecutadas es, como para la suma, 
    $O(n)$ para la resta de dos número de $n$ Cifras. 
 
  \subsubsection{Multiplicación}\label{multiplicacion}
  Posiblemente la operación más importante de todo paquete aritmético.
  Tanto es así que \cite{knuth2} le dedica $23$ páginas, toda su
  sección 4.3.3\footnote{pág. 278 en adelante}.
  
  \paragraph{El método clásico.}
  Utilizando una aproximación análoga al método de ``papel y lápiz'',
  se define el algoritmo \ref{alg:multiplicacion}, con la ligera
  modificación de que las sumas de los productos parciales se van
  realizando entrelazadas con las multiplicaciones, y no al final como
  se suele hacer en los cálculos a mano. Esto es así ya que los
  operandos en estas operaciones parciales serán más pequeños que si
  se espera al final, y dado que el coste temporal de las operaciones
  es proporcional al tamaño de sus operandos, se obtiene una pequeña
  ventaja que, si el cálculo es grande, acaba por notarse.

  \begin{algorithm}
  \caption{Multiplicación en $\mathbb{Z}^+$}\label{alg:multiplicacion}
  \begin{algorithmic}[1]
    \Procedure{Multiplicacion}{entero $u=(u_m u_{m-1} \cdots u_1)_B$, 
                               entero $v=(v_n v_{n-1} \cdots v_1)_B$}
    \State $(w_{m+n} w_{m+n-1} \cdots w_1)_B \gets (0,0,\cdots,0)$ 
    \Comment Representa el resultado.
    \State $acarreo \gets 0$
    \For{$i=1$ hasta $i=n$}
      \For{$j=1$ hasta $j=m$}
        \State $temp \gets (u_j \times v_i + w_{i+j} +
        acarreo)$\label{subalg:multTemp}
        \State $w_{i+j} \gets temp \bmod B$
        \State $acarreo \gets \lfloor temp / B\rfloor$\label{subalg:multAcarreo}
      \EndFor
      \State $w_j \gets acarreo$
    \EndFor
    \State \textbf{devolver} $w$
    \EndProcedure
  \end{algorithmic}
  \end{algorithm}

  Hay varios ``puntos conflictivos'' en este algoritmo \ref{alg:multiplicacion}: 
  la variable $temp$ de la línea \ref{subalg:multTemp} verifica $0
  \leq temp < B^2$, como puede verse (\cite{knuth2}\footnote{pág.
  254}) si tenemos en cuenta que
  inicialmente $acarreo < B$ por
  $(u_j \times v_i + w_{i+j} + acarreo) \leq (B-1)^2 + 2(B-1) = B^2 -
  1 < B$. Esto tiene la importante implicación de que $0 \leq acarreo < B$ en la línea 
  \ref{subalg:multAcarreo}, ya que no tendremos que preocuparnos por
  el desbordamiento de esta variable, como sí hemos de preocuparnos en
  el caso de $temp$. Y es precisamente aquí uno de los puntos en los
  que lo dicho en \ref{eleccionDeLaBase} se aplica: es necesario un
  tratamiento especial de la variable, al ocupar ésta más de los $B$
  bits de la base de trabajo. Este tratamiento una vez más viene dado
  por la CPU Básica, y no sólo eso, ya que además provee de la
  instrucción \texttt{Addmul} que simplifica notablemente la
  codificación del algoritmo a la vez que realiza el citado
  tratamiento especial. Recordando, \texttt{Addmul} suma al producto 
  sus dos argumentos el contenido de la variable interna de la CPU $resto$, 
  y los bits por encima del $B$-ésimo los vuelve a almacenar en dicha
  variable, que resulta ser precisamente lo que hace el bucle
  principal del algoritmo \ref{alg:multiplicacion}. Véase \ref{implementacionCpuBasica}
  para más detalles.
  
  A la vista de los dos bucles anidados, es fácil ver que el número de
  operaciones básicas es $O(nm)$. Si consideramos que el tamaño de los
  factores es el mismo e igual a $n$, se tiene la habitual formulación
  $O(n^2)$ para este algoritmo. Esto, unido a la grandísima
  utilización de esta operación explica el interés en la obtención de
  métodos con una mejor cota. El más conocido de estos métodos optimizados
  se expone a continuación.


  \paragraph{El método de Karatsuba.}\label{karatsuba}
  Expuesto en \cite{knuth2}\footnote{pp. 278, 279},
  \cite{gmp}\footnote{pág. 84}, \cite{riesel}\footnote{pp. 349-352}
  entre otros, este método consiste fundamentalmente en una reordenación de la
  ecuación (\ref{eq:multiplicacionClasica})
  
  \begin{equation}\label{eq:multiplicacionClasica}
    X \times Y = (x_1B + x_0)(y_1B + y_0) = x_1y_1B^2 + (x_1y_0 +
    x_0y_1)B + x_0y_0
  \end{equation}
 
  en la forma de:
  
  \begin{equation}\label{eq:multiplicacionKaratsuba}
    X \times Y = x_1y_1(B^2 + B) + (x_1-x_0)(y_0-y_1)B + x_0y_0(B+1)
  \end{equation}

  La clave reside en que utilizando la ecuación
  (\ref{eq:multiplicacionKaratsuba}), se efectúa una multiplicación
  menos, a cambio de incrementar el número de sumas/restas. Dado que
  la multiplicación es \emph{asintóticamente} más costosa que una suma
  o resta, habrá un punto en el cual el cambio resulte ventajoso. Si
  además se tiene cuidado de realizar las multiplicaciones por la base
  con desplazamientos, se debería obtener un incremento notable en el
  rendimiento. 

  Lo interesante sin embargo, además de ahorrar una multiplicación, es
  plantear el método de forma recursiva, dentro de una estrategia
  ``divide y vencerás'' tal como se muestra en el algoritmo
  \ref{alg:karatsuba}. Se observa asimismo que los factores han
  que ser de aproximadamente del mismo tamaño para que tenga sentido
  utilizar este método: si difiriesen demasiado, en muchas iteraciones
  estaríamos aún realizando multiplicaciones por cero cuando de haber
  utilizado el método clásico, ya se habría terminado.
 
%  \begin{center}\label{vector_repr}
%    \begin{tabular}{|>{\centering}m{3cm}|>{\centering}m{3cm}|}
%      \hline
%        $x_1$ & 
%        $x_0$ \tabularnewline
%       \hline
%       \hline
%        $y_1$ & 
%        $y_0$ \tabularnewline
%       \hline    
%    \end{tabular}
%    \\*
%    \begin{tabular}{>{\raggedright}m{3cm}>{\raggedleft}m{3cm}}
%			Más peso & 
%      Menos peso \tabularnewline
%		\end{tabular}	
%  \end{center}


  
  
  \begin{algorithm} 
  \caption{Multiplicación Karatsuba} \label{alg:karatsuba}
  \begin{algorithmic}[1] 
    \Procedure{Karatsuba}{entero $X$, entero $Y$}
    \State $m \gets \lfloor \frac{\log_2{X}}{2} \rfloor$
    \If{$m > UMBRAL$}
      \State $x_0 \gets X \bmod 2^{m}$
      \State $x_1 \gets \lfloor \frac{X}{2^{m}} \rfloor $
      \State $y_0 \gets Y \bmod 2^{m}$
      \State $y_1 \gets \lfloor \frac{Y}{2^{m}} \rfloor $
      \State
      \State $P_1 \gets Karatsuba(x_1, y_1)$
      \State $P_2 \gets Karatsuba((x_1 - y_0),(y_0 - y_1))$
      \State $P_3 \gets Karatsuba(x_0, y_0)$
      \State
      \State $S_{11} \gets P_1 \times B^2$
      \State $S_{12} \gets P_1 \times B$
      \State $S_{2} \gets P_2 \times B$
      \State $S_{31} \gets P_3 \times B$
      \State $S_{32} \gets P_3$
      \State
      \State $resultado = (S_11 + S_12) + S_2 + (S_31 + S_32)$
    \Else
      \State Multiplicación clásica
    \EndIf
    \EndProcedure
  \end{algorithmic}
  \end{algorithm}
  
  El cálculo de la complejidad temporal es muy sencillo: $3$
  multiplicaciones ``básicas'' (por debajo del umbral considerado, que
  se tratará mas adelante) por cada partición en dos posible arroja
  una complejidad de $O(n^{\log_2{3}})$. En símbolos:
  \begin{equation}\label{eq:defComplejidadKaratsuba}
   T(n) = \left\{ 
    \begin{array}{ll}
      3T(n/2) & \textrm{si $n > 2$}\\
      1 & \textrm{si no}\\
    \end{array} \right. 
  \end{equation}
  Expandiendo la recurrencia,
  \begin{displaymath}
   T(n) = 3T(n/2) = 3(3T(n/{2^2})) = \cdots = 3^{i}T(n/{2^{i}}) 
    \stackrel{i=\log_2{n}}{\Longrightarrow} 3^{\log_2{n}} = n^{\log_2{3}}
    \approx n^{1.585} 
  \end{displaymath}
  Este resultado es muy importante, ya que supone una mejora
  asintótica de aproximadamente el $21\%$.

  \subparagraph{El cálculo del umbral óptimo.} Determinar a partir de
  qué tamaño es preferible utilizar el método de Karatsuba en vez del clásico 
  es fundamental. Como caso extremo, si ese umbral (véase algoritmo
  \ref{alg:karatsuba}) fuese establecido a $1$, tan sólo se tendría
  una versión recursiva de la multiplicación, aunque considerablemente
  peor que la clásica, ya que aunque asintóticamente las sumas son
  preferibles a la multiplicación, en el caso base (operandos en base
  $B$) se pueden considerar equivalente, y la ecuación
  (\ref{eq:multiplicacionKaratsuba}) realiza un número de sumas mayor
  que la (\ref{eq:multiplicacionClasica}) a cambio de un solo
  producto. Además, la sobrecarga producida por todo método recursivo
  también pasaría factura. En el otro sentido, un umbral demasiado
  grande tendría prácticamente el mismo resultado (en tiempo de
  computación) que utilizar directamente el método clásico.

  Se tiene que encontrar, pues, el punto en el cual empiece a notarse la
  mayor complejidad asintótica de la multiplicación ($O(n^2)$) frente
  a la suma ($O(n)$). Para esto ha de abandonarse el plano teórico y
  pasar a realizar pruebas sobre las implementaciones concretas, única
  manera de determinar las variables ocultas de las cotas de
  complejidad. A la vista de la ecuación
  (\ref{eq:defComplejidadKaratsuba}), lo que se busca es el mayor $k$
  para el cual $3T(k/2) < T(k)$. A partir de dicho $k$, utilizar el
  método recursivo de Karatsuba será ventajoso. Veamos datos
  concretos: En la figura \ref{subfig:vistaGeneralKaratsuba} se
  muestran tiempos de la ejecución de la multiplicación de dos
  factores escogidos al azar. La línea titulada ``Triple de mitad'' se
  corresponde a ``Original'' escalada para satisfacer la anterior
  inecuación, siendo el $k$ buscado el punto de corte más alejado del origen 
  sobre el eje de ordenadas. En \ref{subfig:detalleKaratsuba} se
  amplía la zona interesante de la gráfica para apreciar el corte con
  mayor precisión. A la vista de esto (y de los datos numéricos
  utilizados para la realización de las gráficas que no se incluyen
  aquí por brevedad), se puede concluir que \emph{para esta
  implementación} un umbral óptimo es $k = 32$. En consecuencia, el
  umbral del algoritmo \ref{alg:karatsuba} tendrá el doble de este
  valor, $64$, para que, a la multiplicación básica llegue un número
  de tamaño $32$ cifras o menor.
  
  \begin{figure} 
    \begin{center}
        \subfigure[Vista general]{\label{subfig:vistaGeneralKaratsuba}
        \input{graficaUmbralKaratsuba.tex}
      }
      \subfigure[Detalle]{\label{subfig:detalleKaratsuba}
        \input{graficaUmbralKaratsubaDetalle.tex}
      }
      \end{center}
      \caption{Umbral óptimo multiplicación de Karatsuba}
    \end{figure}

    Como comprobación práctica de este desarrollo se representa en la
    figura \ref{fig:comparacionClasicoVsKaratsuba64} el tiempo contra
    el tamaño de los factores en la multiplicación mediante cada
    método. Para el umbral de Karatsuba, se utiliza el recién
    calculado valor de $64$. Nótese la gran ganancia en la
    multiplicación de números de $3000$ dígitos en base $B$ (para
    $B=32$, esto serían $96000$ bits, aproximadamente $29000$ cifras
    decimales), de unos $305000$ microsegundos, esto es, unas $3$
    décimas de segundo.
    
    \begin{figure}\label{fig:comparacionClasicoVsKaratsuba64}
      \begin{center}
        \input{graficaComparacionNormal_K64.tex}
      \end{center}
      \caption{Comparación método clásico vs. Karatsuba 64}
    \end{figure}

    Para concluir, y siguiendo con la política de la comprobación
    práctica, en la figura \ref{fig:comparacionKaratsubas} se
    representa la comparación entre multiplicaciones por el método de
    Karatsuba con distintos umbrales. Se verifica pues que $64$ es el
    valor óptimo (al menos el que se ha podido obtener con la 
    precisión de trabajo utilizada;
    el medir tiempos del orden de microsegundos es relativamente
    complejo, ya que nos movemos en la escala de tiempos de las
    propias rutinas del lenguaje y se producen por tanto numerosas
    ``interferencias'').
   
    \begin{figure}\label{fig:comparacionKaratsubas}
      \begin{center}
        \input{graficaComparacionKaratsubas.tex}
      \end{center}
      \caption{Comparación Karatsuba con distintos umbrales}
    \end{figure}

  \subsubsection{División}\label{division}
    Es el algoritmo más complejo dentro de las operaciones fundamentales.
    La referencia fundamental es de nuevo \cite{knuth2}\footnote{pp.
    255-263}, donde se expone un desarrollo del método que todos
    aprendemos en la escuela cuando se nos presenta por primera vez
    la división; al igual que para el caso de la multiplicación, el
    algoritmo clásico se basa en la adaptación de estos métodos de
    la infancia.

    Para justificar el algoritmo son necesarios algunos resultados
    previos:
    \paragraph{Estimación del cociente} 
    \begin{definicion}[Estimación de $\hat{q}$
      (\cite{knuth2})]\label{defAproxQ}
      Por \cite{knuth2} se tiene que, dado $u=(u_{n+1} u_{n} \cdots u_1)_B$
    y $v=(v_{n} v_{n-1} \cdots v_1)_B$ dos números en base $B$ tales
    que $\frac{u}{v} < B$, 
    $\hat{q} = \min\left( \lfloor\frac{u_{n+1}B+u_n}{v_n}\rfloor,
    B-1\right)$
    \end{definicion}
    Esta aproximación del cociente resulta ser razonablemente buena, y
    se obtiene de una forma muy similar a la realizada mentalmente al
    dividir ``a mano''. La bondad de esta aproximación se explica a la
    vista de los siguientes resultados, cuya demostración no se
    incluye por brevedad y puede ser encontrada en
    \cite{knuth2}\footnote{pp. 256, 257}. Nótese, sin embargo, que se han
    introducido cambios en la notación (en concreto, en los
    subíndices).
    \begin{teorema}[Teorema A]\label{defCotaQ}
      Para la $\hat{q}$ de la definición \ref{defAproxQ} y $q =
      \lfloor\frac{u}{v}\rfloor$, $\hat{q} \geq q$.
    \end{teorema}
    \begin{teorema}[Teorema B]\label{defCotaQNorm}
      Si $v_n \geq \lfloor\frac{b}{2}\rfloor$, entonces 
      $\hat{q}-2 \leq q \leq \hat{q}$.
    \end{teorema}

    Es decir, para cualquier base, el error que se comete al aproximar
    el cociente por la definición \ref{defAproxQ} es a lo sumo de $2$
    unidades si el dígito más significativo del divisor es mayor o
    igual que la mitad de la base de trabajo. Este requisito, que
    puede verse como una normalización previa de los datos, es fácil
    de satisfacer cuando se trabaja en base $2$ ---o con una potencia de
    $2$, lo cual en última instancia será lo que se haga siempre en un 
    ordenador digital--- sin más que desplazar los bits del divisor $v$ las
    posiciones a la izquierda necesarias para que el dígito binario
    más significativo de $v_n$ sea $1$.

    Así pues, a grandes rasgos el algoritmo clásico de división opera
    mediante ``prueba y error'', aproximado el cociente $q$ mediante
    $\hat{q}$, corrigiendo la aproximación si se detecta errónea en un
    paso posterior. El teorema \ref{defCotaQNorm} garantiza que como
    máximo sólo habrá de corregirse este valor en dos ocasiones.
 
    \paragraph{}
    Antes de mostrar el algoritmo general, en el algoritmo
    \ref{alg:divisionSimple} 
    se detalla el caso concreto en el que el divisor es un sólo dígito
    en base $B$, que resulta ser el ejercicio 16 de la sección 4.3.1
    de \cite{knuth2}.

    \begin{algorithm}
      \caption{Algoritmo clásico de división con divisor simple}\label{alg:divisionSimple}
      \begin{algorithmic}[1]
      \Procedure{DivisionSimple}{entero $u=(u_n u_{n-1} \cdots u_1)_B$, cifra $v=(v_1)_B$}
      \If{ $v = 0$ }
        \State Lanzar error de división por cero.
      \Else
        \State $r \gets 0$
        \For{$i=n$ hasta $i = 0$} 
          \State $q_i \gets \lfloor\frac{rB + u_i}{v_1}\rfloor$
          \State $r \gets (rB + u_i) \bmod v_1$
        \EndFor
        \State \textbf{devolver} $(q_n q_{n-1} \cdots q_1)_B$, $r$
      \EndIf
      \EndProcedure
      \end{algorithmic}
    \end{algorithm}

    Y en esta ocasión el método sí es idéntico al ``manual''. Un
    pequeño apunte respecto a la implementación real en la librería:
    se aprecia en situaciones como ésta las ventajas del diseño del
    conjunto de operaciones de la CPU básica (véase
    \ref{implementacionCpuBasica}), ya que en cada iteración el resto
    $r$ es calculado automáticamente y utilizado también de forma
    automática como la parte alta del dividendo en la siguiente
    división. Para más detalles se remite al lector al propio código
    fuente.
      
    Se ve claramente que la complejidad es $O(n)$.
    
    En el algoritmo \ref{alg:division} se muestra el algoritmo
    completo de división para el caso en el que el divisor es $\geq
    B$.
    
    \begin{algorithm}
      \caption{Algoritmo clásico de división}\label{alg:division}
      \begin{algorithmic}[1]
        \Procedure{División}{entero $u$, entero $v$}
        \Require $u=(u_{m+n} u_{m+n-1} \ldots u_1)_B$, $v=(v_n v_{n-1}\ldots v_1)_B$ no
        negativos. $v_1 \neq 0$ y $n > 1$.

        \Comment{Normalización. Para tener $v_1 >= \lfloor B/2 \rfloor$}
        \State $d \gets \texttt{Bfffo($v_1$)}$
        \Comment Véase \ref{implementacionCpuBasica}.
        \State $(u_{m+n+1} u_{m+n} \cdots u_1)_B \gets (u_{m+n} \cdots u_1)_B \times 2^d$
        \State $(v_n v_{n-1} \cdots v_1)_B \gets (v_n v_{n-1} \cdots v_1)_B \times 2^d$

        \For{ $j = (m+n+1) $ hasta $j \leq m$ }
        \If{ $u_j = v_n$}
            \State $\hat{q} \gets B-1$
          \Else
            \State $\hat{q} \gets \lfloor \frac{u_{j}B+u_{j-1}}{v_n}
            \rfloor$\label{subalg:divSimple}
          \EndIf
          \While{ $v_{n-1}\hat{q} > (u_{j}B+u_{j-1}-\hat{q}v_n)B + u_{j-2}$}
            \State $\hat{q} \gets \hat{q} - 1$
          \EndWhile
          
          $(u_ju_{j-1}\ldots u_{j-n})_B \gets (u_ju_{j-1}\ldots u_{j-n})_B - 
            \hat{q}(v_n v_{n-1} \ldots v_{1})_B$
          \Comment{$(u_j u_{j-1}\ldots u_{j-n})_B$ debe mantenerse
          positivo. Si fuera negativo se le sumaría $B^{n+1}$ con el fin de
          obtener su representación en complemento a $b$}

          \State $q_{j-n} \gets \hat{q}$
          \If{$(u_j u_{j-1}\ldots u_{j-n})_B$ fue negativo}
            \State $q_j \gets q_j -1$
            \State $(u_j u_{j-1}\ldots u_{j-n})_B \gets 
            (u_j u_{j-1}\ldots u_{j-n})_B + (0 v_n v_{n-1}\ldots v_1)_B$
            
            \Comment{Ignorar el acarreo que se produce a la izquierda de
            $u_j$, debido al complemento en base $B$}
          \EndIf
        \EndFor
        
        \State $(u_{m-1} u_{m-2}\ldots u_{m-n})_B \gets 
        \lfloor\frac{(u_{m-1}u_{m-2}\ldots u_{m-n})_B}{2^d}\rfloor$ 
        \Comment{Desnormalizar, para el resto}
        
        \State \textbf{devolver} $(q_{m+1}q_{m}\ldots q_{1})_B$ como cociente.
        \State \textbf{devolver} $(u_{m-1}u_{m-2}\ldots u_{m-n})_B$ como resto.


        \Ensure Se forma el producto $\lfloor u/v \rfloor = (q_{m+1} q_m \ldots
        q_1)_B$ y el resto $u \bmod v = (r_n r_{n-1}\ldots r_1)_B$
      \EndProcedure
      \end{algorithmic}
    \end{algorithm}

    Nótese que la probabilidad de que el nuevo dividendo tras la resta
    sea negativo es del orden de $2/B$.

    Una forma de verlo es:
    \begin{eqnarray}
    \textrm{Si } & 
    \left. 
    \begin{array}{l}
      v_1 \geq \lfloor b/2 \rfloor \\ 
      v_2\hat{q}\leq b\hat{r}+u_2 \\
      \hat{q} \neq q  
    \end{array}\right\} &
    \Longrightarrow u \bmod u \geq (1-2/b)v
    \end{eqnarray}
    Por tanto en la inmensa mayoría de los casos se tendrá que $q_j = \hat{q}$
    excepto en raras ocasiones (precisamente en las que la resta para
    conformar el nuevo dividendo tiene un resultado $<0$). Si
    suponemos $B=2^{32}$, $p = 2/B \approx 0.466 \times 10^{-10}$, lo
    cual es del mismo orden que la probabilidad de caer fulminado por
    un rayo a lo largo de un día (\cite{schneier}\footnote{pág. 18}).
    Un caso en el que sí ocurre es\\
    $11111111111111111111111111111111111111111 / 2587007151709662543404209433542 \\*
    \approx 4294967295.999999999998$ con $B = 2^{32}$.


    La complejidad se estima a la vista de que el bucle sobre la
    variable $j$ se ejecuta $n+1$ veces, y en cada una de estas
    iteraciones se efectúa en el peor caso hasta tres multiplicaciones
    y una división por un entero ``simple'' (una \index{Cifra}{Cifra}). Esta
    división será la efectuada en la línea \ref{subalg:divSimple} por
    el algoritmo \ref{alg:divisionSimple}, pero dado que
    el dividendo tendrá siempre tan sólo dos cifras en base $B$, 
    esta operación se considera $O(1)$. Además, se efectúan también
    cuatro restas y dos sumas sobre elementos que podemos considerar por simplicidad
    de tamaño $m$ siempre. En resumen, son todo operaciones de
    complejidad lineal $O(m)$, en un bucle de $n+1$ iteraciones, con
    lo que se concluye una complejidad global de $O(m(n+1)) = O(mn)$.
    Nos quedamos con $O(n^2)$ como viene siendo habitual en estos
    casos, considerando dividendo y divisor del mismo tamaño e igual a
    $n$.
    \subsubsection{Potenciación}
    %todo
    
\section{Algoritmos sobre $\mathbb{R}$}
\subsection{Introducción}
 Los problemas derivados de implementar un conjunto como $\mathbb{R}$
 pasan prácticamente siempre por temas pertenecientes al campo del
 Cálculo Numérico. Es por esto que esta librería no da soporte a la
 gran mayoría de funciones que operan en este conjunto (funciones
 trigonométricas, logaritmos, radicación, etc. ), al centrarse en el
 trabajo con $\mathbb{Z}$ para la criptografía y la Teoría de Números. 
 Aún así, se han implementado mecanismos de redondeo y tratamiento de
 la precisión, además de la suma, resta, multiplicación, división y
 potenciación (entera).

 La expansión de la librería hacia un soporte más completo de
 $\mathbb{R}$ resultaría muy interesante, estando gran parte de
 trabajo hecho proporcionando los cimientos de este soporte íntegro.

  \subsection{Representación}
  Apoyándose en $\mathbb{Z}$, la forma elegida de representación de
  reales, una variación de lo propuesto en
  \cite{knuth2}\footnote{Sección 4.2, pág. 198 en adelante} para la
  implementación de aritmética en punto flotante, es la siguiente:

  \begin{center}\label{vector_repr}
    \begin{tabular}{|>{\centering}m{5cm}|>{\centering}m{2cm}|}
      \hline
        $m \in \mathbb{Z}$ & 
        CifraSigno \tabularnewline
       \hline
       \multicolumn{1}{c}{$\stackrel{\underbrace{\hspace{5cm}}}{{\textrm{mantisa}}}$} &
       \multicolumn{1}{c}{$\stackrel{\underbrace{\hspace{2cm}}}{{\textrm{exponente}}}$ }
		\end{tabular}	
  \end{center}
 \index{mantisa}
 \index{exponente}
 correspondiendo al número 
 \begin{equation}\label{eq:defRepresentacionR}
   (m,e) = m \times 2^e
 \end{equation}
 con $m$ el entero y
 $e$ entero de precisión simple con signo, como se define en
 \ref{algoritmosSobreZ}. De esta forma es posible representar números
 reales (obviamente no todos, véase \ref{conjuntosNumericos}) con una
 precisión arbitraria que marcaría el número de bits del exponente
 $e$.
 
 La justificación de esta representación es inmediata: El exponente $e$ 
 no representa más que la posición ``de la coma'', en este caso binaria.
 De tener un valor positivo, el número será en realidad un entero, de
 valor igual a la mantisa $m$ desplazada $e$ posiciones hacia la
 izquierda (en base $2$, recordemos la ecuación
 \ref{eq:defRepresentacionR}). Si es negativo, el valor absoluto de
 $e$ marcará la posición del punto binario empezando por el dígito
 menos significativo:
 \[
    (m_n \cdots m_{k+1} m_k m_{k-1} \cdots m_1)_2 \times 2^{-k} =
    (m_n \cdots m_{k+1} \; \textbf{.} \; m_k m_{k-1} \cdots m_1)_2
 \]
%  //  ____________________________     _____
%  // |_kb_|__32b__|__32b__|__32b__|   |_exp_|   
%  //                                    ^^^
%  //  <----- l bits ---> < k bits->   valor -k    
%  //  p ej.             ^
%  //  La posicion del "punto binario" seria la indicada.
%  //  Asi que separo en un Z los "l" bits indicados y eso se
%  //  interpreta por operator<< de salida de Z.
%  //  Para los "k" bits "fraccionarios" se aplica el proceso sgte:
%  //  
%  //  (.u-1 u-2 u-3 ... u-p) con "p" la precisión;
%  //  u-1 = floor(u*10)
%  //  u-2 = floor({u*10}*10)
%  //  u-3 = floor({{u*10}*10}*10)
%  //  ...
%  //
%  //  con {k} = k - floor(k); esto es, la parte fraccionaria

\subsection{\index{normalización}{Normalización} y 
  \index{redondeo}{redondeo}}\label{normalizacionYRedondeo}
  El proceso de normalización al que se somete los datos del número
  real no sigue los habituales métodos
  de normalización, como es el expuesto en
  \cite{knuth2}\footnote{pág. 199, sección B. ``Normalized
  calculations''} ya que la \index{mantisa}{mantisa} ha de ser un entero. 
  Sí se siguen, sin embargo, las directrices del redondeo, como se expone más
  adelante.

  Lo que se ha dado en llamar \emph{normalización} en esta librería se
  corresponde fundamentalmente con los siguientes pasos:
  \begin{enumerate}
    \item Asegurar la unicidad de la representación del cero:
      $(mantisa = 0) \Longrightarrow (exponente = 0)$.
      \label{puntoUnoNorm}
    \item Ajuste de la longitud de la mantisa a la precisión de
      trabajo.
      \label{puntoDosNorm}
    \item Eliminación de las potencias de $2$ de la mantisa y su
      traslado al exponente.
      \label{puntoTresNorm}
  \end{enumerate}

  La razón de ser del punto \ref{puntoUnoNorm} es clara. De no estar
  presente, habría $2^{\log_2{CifraSigno_{max}}}$ posibles
  presentaciones del cero en $\mathbb{R}$. Pese a que quizás esto
  pudiera ser atajado sin demasiadas dificultades en la programación
  (sería $0$ todo aquello de $mantisa = 0$), no parece que sea
  algo coherente.
  El papel del punto \ref{puntoDosNorm} está claro, mientras que el
  del punto \ref{puntoTresNorm} requiere un poco más de explicación:
  el hecho de trasladar todas las potencias de $2$ presentes en el
  número al exponente responde a que por una parte, el hacerlo es
  directo (véase ecuación (\ref{eq:defRepresentacionR})) y la mantisa
  reduce su tamaño en un bit por cada potencia de $2$ eliminada, que
  redunda en datos a procesar menores en las operaciones, que como se
  verá en la sección \ref{operacionesR}, mejora las cotas de
  complejidad.


  El \emph{redondeo} de los datos es un tema un poco más complejo.
  Se ha adoptado el siguiente método (\cite{knuth2}
  \footnote{pág. 201, algoritmo N, paso N5}):
  (Nótese que lo que \cite{knuth2} denomina por $b$, nosotros lo
  denominamos por $B$ y $f$ es la mantisa $m$.)
  \begin{quotation}
    Round $m$ to $p$ places. (We take this to mean that $m$ is changed 
    to the nearest multiple of $B^{-p}$. It is posible that $(B^p m)
    \bmod 1 = \frac{1}{2}$ so that there are \emph{two} nearest
    multiples; if $B$ is even, we choose the one that makes $B^p f +
    \frac{1}{2}b$ odd [\ldots])\footnote{Símbolos adaptados desde el
    original.}
  \end{quotation}
  junto a que\footnote{\textit{Ibídem}, pág. 222}:
  \begin{quotation}
    For even radices, there is reason to prefer the following
    rule: ``Round to even when $b/2$ is odd, round to odd when $b/2$
    is even.''
  \end{quotation}
  Esto es, a la hora de redondear un número, se toma el múltiplo más
  cercano a $B^{-p}$, que es lo mismo que aplicar el habitual criterio
  de aumentar en una unidad la nueva cifra menos significativa si la
  cifra eliminada más significativa era $\geq 6$, no haciendo nada si
  ésta era $\leq 4$. Para el caso de que fuese igual a $5$ (que
  \cite{knuth2} expresa como $(b^p f) \bmod 1 = \frac{1}{2}$), se
  adopta el citado criterio de ``Round to even'' o ``Redondeo al par''
  que consiste en hacer que la nueva cifra menos significativa sea
  par. La elección de este criterio viene motivada por el segundo
  párrafo citado, donde se indica que se use éste cuando la base 
  de trabajo dividida entre $2$ es impar, y es claro que para nosotros
  se cumple esta condición, ya que en última instancia estamos
  utilizando $2$ como base de trabajo.
    
 
  \subsection{Operaciones}\label{operacionesR}
    Como factor común a todas estas operaciones está el que nos valemos 
    de la implementación de $\mathbb{Z}$ para operar. Esto viene
    motivado por el hecho de que la \index{mantisa}{mantisa} sea un entero.
    Así, la gestión de signos también se
    delega a la implementación de $\mathbb{Z}$, quedando por tanto
    codificado el signo en las mantisas.  
 
  \subsubsection{Suma}
   Esta operación, al contrario que para $\mathbb{Z}$, reviste cierta
   complejidad derivada del control del redondeo y las cifras
   significativas. En el algoritmo \ref{alg:sumaR} se detalla el
   esquema utilizado.
    \begin{algorithm}
      \caption{Suma en $\mathbb{R}$}\label{alg:sumaR}
      \begin{algorithmic}[1]
        \Procedure{Suma}{real $a=(mant_a,exp_a)$, 
                         real $b=(mant_b,exp_b)$}

        \State $tam_a \gets tamaño(a)$
        \State $tam_b \gets tamaño(b)$
        \State $difTamaños \gets | tam_a - tam_b |$

        \If{ $exp_a > exp_b$ }
          \State $difExp \gets (exp_a - exp_b)$
          \If{ $difExp \geq (precisionTrabajo + difTamaños)$ }
            \State \Comment El sumando de la derecha es mucho menor que el de
            la izquierda: No se suma nada, ya que se perdería por la
            precisión de trabajo de todas formas.
            \State \textbf{devolver} $a$
          \Else
            \Comment Los exponentes han de ``equilibrarse''.
            \State $mant_a \gets (mant_a \times 2^{difExp})$
            \State $exp_a \gets exp_b$
            \State $mant_a \gets (mant_a + mant_b)$
            \State \Comment Invocar en este punto a la función de
            normalización (véase \ref{normalizacionYRedondeo}).
            \State \textbf{devolver} $a$
          \EndIf
        \ElsIf{ $exp_a < exp_b$ }
          \State $difExp \gets exp_b - exp_a$
          \If{ $difExp \geq (precisionTrabajo + difTamaños)$ }
            \State \Comment El sumando de la izquierda es mucho menor que el de
            la derecha: No se suma nada, ya que se perdería por la
            precisión de trabajo de todas formas.
            \State \textbf{devolver} $b$
          \Else
            \Comment Los exponentes han de ``equilibrarse''.
            \State $mant_b \gets (mant_b \times 2^{difExp})$
            \State $mant_a \gets (mant_a + mant_b)$
            \State \Comment Invocar en este punto a la función de
            normalización (véase \ref{normalizacionYRedondeo}).
            \State \textbf{devolver} $a$
          \EndIf
        \Else \Comment Exponentes iguales
          \State $mant_a \gets (mant_a + mant_b)$
          \State \Comment Invocar en este punto a la función de
            normalización (véase \ref{normalizacionYRedondeo}).
          \State \textbf{devolver} $a$
       \EndIf
        \EndProcedure
      \end{algorithmic}
    \end{algorithm}
    
    Respecto al algoritmo, es importante la idea de comprobar si
    alguno de los sumandos es despreciable (esto vendrá dado en
    función de la precisión de trabajo) frente al otro, de tal forma
    que la suma fuese fútil. Una vez comprobado esto, quedará el hacer
    que los exponentes tengan el mismo valor mediante operaciones de
    desplazamiento de bits ($O(n)$) y sumar las mantisas. Como en
    todas las demás operaciones, el último paso consistirá en la
    normalización y redondeo del número resultante.

    La complejidad del método es análoga a la suma de $\mathbb{Z}$;
    esto es, $O(n)$ (en rigor, $O(n+m)$ para $n$, $m$ el tamaño de las
    mantisas de $a$ y $b$ respectivamente), aunque las constantes
    ocultas serán mayores ya que influyen también las operaciones de
    desplazamiento de bits para la igualación de exponentes ($O(n)$) y
    la normalización y redondeo ($O(n)$).
    
   \subsubsection{Resta}
   Operación muy similar a la suma, se muestra en el algoritmo
   \ref{alg:restaR}, siendo válido todo lo dicho para la suma también
   en este caso.
  \begin{algorithm}
    \caption{Resta en $\mathbb{R}$}\label{alg:restaR}
    \begin{algorithmic}[1]
      \Procedure{Resta}{real $a=(mant_a,exp_a)$, 
                        real $b=(mant_b,exp_b)$}
  
        \State $tam_a \gets tamaño(a)$
        \State $tam_b \gets tamaño(b)$
        \State $difTamaños \gets | tam_a - tam_b |$

        \If{ $exp_a > exp_b$ }
          \State $difExp \gets (exp_a - exp_b)$
          \If{ $difExp \geq (precisionTrabajo + difTamaños)$ }
            \State \Comment El sustraendo es mucho menor que el 
            minuendo: No se resta nada, ya que se perdería por la
            precisión de trabajo de todas formas.
            \State \textbf{devolver} $a$
          \Else
            \Comment Los exponentes han de ``equilibrarse''.
            \State $mant_a \gets (mant_a \times 2^{difExp})$
            \State $exp_a \gets exp_b$
            \State $mant_a \gets (mant_a - mant_b)$
            \State \Comment Invocar en este punto a la función de
            normalización (véase \ref{normalizacionYRedondeo}).
            \State \textbf{devolver} $a$
          \EndIf
        \ElsIf{ $exp_a < exp_b$ }
          \State $difExp \gets exp_b - exp_a$
          \If{ $difExp \geq (precisionTrabajo + difTamaños)$ }
            \State \Comment El minuendo es mucho menor que el 
            sustraendo: No se resta nada, ya que se perdería por la
            precisión de trabajo de todas formas. Sin embargo, si ha
            de realizarse el cambio de signo del sustraendo.
            \State $mant_b \gets (mant_b \times -1)$
            \State \textbf{devolver} $b$
          \Else
            \Comment Los exponentes han de ``equilibrarse''.
            \State $mant_b \gets (mant_b \times 2^{difExp})$
            \State $mant_a \gets (mant_a - mant_b)$
            \State \Comment Invocar en este punto a la función de
            normalización (véase \ref{normalizacionYRedondeo}).
            \State \textbf{devolver} $a$
          \EndIf
        \Else \Comment Exponentes iguales
          \State $mant_a \gets (mant_a - mant_b)$
          \State \Comment Invocar en este punto a la función de
            normalización (véase \ref{normalizacionYRedondeo}).
          \State \textbf{devolver} $a$
       \EndIf
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
  

  \subsubsection{Multiplicación}
   Teniendo presente la representación elegida para este conjunto, la
   multiplicación se reduce a la multiplicación de las mantisas y la
   suma de los exponentes seguido de la normalización, como es
   habitual. Resulta el algoritmo \ref{alg:multiplicacionR}.
  \begin{algorithm}
    \caption{Multiplicación en $\mathbb{R}$}\label{alg:multiplicacionR}
    \begin{algorithmic}[1]
      \Procedure{Multiplicación}{real $a=(mant_a,exp_a)$, 
                                 real $b=(mant_b,exp_b)$}
        \State $mant_a \gets (mant_a \times mant_b)$
        \State $exp_a \gets (exp_a + exp_b)$
        
        \State \Comment Invocar en este punto a la función de
          normalización (véase \ref{normalizacionYRedondeo}).
        \State \textbf{devolver} $a$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
  
  Es evidente que dado que la multiplicación de las mantisas, parte
  costosa del algoritmo, es la de $\mathbb{Z}$, este algoritmo será de
  la misma complejidad que la multiplicación de enteros (aunque las
  constantes ocultas serán mayores, por ejemplo el coste $O(n)$ de la
  normalización/redondeo).
  
   \subsubsection{División}
   Como en la multiplicación, es fácil idear el método a utilizar a la
   vista de la representación: división entera de las mantisas y 
   resta de los exponentes. Ahora bien, esta división entera hace que
   se ``pierda información'', por lo cual hay que tener cuidado y
   tener en cuenta la precisión de trabajo para que esto no suceda. En
   concreto, véase el algoritmo \ref{alg:divisionR}, línea
   \ref{subalg:divisionRprec}.
  
   \begin{algorithm}
    \caption{División en $\mathbb{R}$}\label{alg:divisionR}
    \begin{algorithmic}[1]
      \Procedure{División}{real $a=(mant_a,exp_a)$, 
                           real $b=(mant_b,exp_b)$}
        \If{ $b =  0$ }
          \State Lanzar error de división por cero.
        \Else
          \State $k \gets (precision - \log_2{mant_a} + \log_2{mant_b} -1)$
          \If{ $k < 0$ }
            \State $k \gets 0$
          \EndIf
          \State $mant_a \gets (mant_a \times 2^k)$ \label{subalg:divisionRprec}
          \State $mant_a \gets \lfloor(mant_a / mant_b)\rfloor$
          \State $exp_a \gets (exp_a - exp_b)$
          \State \Comment Invocar en este punto a la función de
            normalización (véase \ref{normalizacionYRedondeo}).
          \State \textbf{devolver} $a$
        \EndIf
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}
  
  Como en casos anteriores, la complejidad del método depende de la de
  las rutinas en $\mathbb{Z}$ utilizadas; en este caso la división
  entera, el desplazamiento de bits y la normalización/redondeo. Así
  pues, la división entera domina asintóticamente con $O(nm) \approx
  O(n^2)$ sobre los $O(n)$ de las otras dos operaciones.
  
\section{Algoritmos sobre $\mathbb{Z}_n$}
  \subsection{Representación}
  La representación de $\mathbb{Z}_n$ será análoga a la de
  $\mathbb{Z}$, ya que la única diferencia será la ``acotación'' del
  entero por el módulo reductor $n$.

  
  \subsection{Cálculo del inverso}
  $\mathbb{Z}_n$ es, en general, un anillo conmutativo. Si $n$ resulta
  ser primo, pasará a ser un cuerpo, ya que se gozará de inverso para
  todo elemento del mismo distinto de $0$. Tanto en este último caso como para los 
  elementos invertibles del anillo (aquellos elementos del anillo
  coprimos con el módulo reductor $n$), es necesario disponer de
  métodos que calculen su inverso. 

  Para dicho cálculo del inverso, cuando éste sea posible, nos
  valemos de la versión ``extendida'' del máximo común divisor (véase
  \ref{gcdExtendido}). La justificación es sencilla: Ya que un
  elemento $a$ será invertible si y sólo si es coprimo con el módulo
  reductor $n$, tenemos que $\gcd(a,n)=1$. Entonces, en base a la
  representación del máximo común divisor como una combinación lineal
  de sus argumentos, se tiene 
  \begin{eqnarray}
    1 &=& Ca + Dn  \\
    1-Dn &=& Ca \\
    1 & \equiv & Ca \pmod{n}
  \end{eqnarray}
  lo cual es precisamente la definición de inverso, siendo ésta $C
  \equiv a^{-1} \pmod{n}$. 
  
  En resumen, sin más que verificar la coprimalidad del número a
  invertir y el módulo reductor, sólo habrá que considerar el
  coeficiente del número a reducir en la representación del máximo
  común divisor como una combinación lineal.
    
  \subsection{Potenciación}\label{potEnZn}
  La operación de potenciación modular es de las más importantes en
  criptografía. Prácticamente todos los esquemas criptográficos que se
  sirven de aritmética de números grandes (esto es, esquemas
  criptográficos de clave pública) la utilizan, y su implementación
  correcta y eficiente es por consiguiente de vital importancia.

  En general, se pueden adoptar dos enfoques:
  \begin{itemize}
    \item Utilización de un método \textit{ad hoc} para la realización
      de la potenciación.
    \item Valerse de los métodos de potenciación de $\mathbb{Z}$ con
      reducciones cada número determinado de iteraciones para mantener
      el número en un tamaño óptimo, acorde a la complejidad de los
      métodos de potenciación en cuestión.
  \end{itemize}
  La librería incorpora ambos, representados respectivamente por el
  método de potenciación-multiplicación-reduccion de Montgomery y el método de 
  reducción de Barrett.


  \subsubsection{Método de Montgomery}
  Este método de potenciación es una aplicación del método de
  multiplicación modular de Montgomery, el cual a su vez utiliza el
  denominado, sin sorpresas, método de reducción de Montgomery.
  En \cite{guanMont} puede leerse una clara descripción (el artículo
  son tan sólo 3 páginas) del la multiplicación y la reducción.
   Un análisis más en profundidad y
  comparativa de posibles implementaciones puede encontrarse en
  \cite{compMont}. 

  La reducción de Montgomery se apoya en lo siguiente
  (\cite{handbook}\footnote{pág. 601, ``Fact'' 14.29}):
  \begin{teorema}[Reducción de Montgomery]
    Sean dos enteros $m$ y $R$ coprimos, $m' \equiv -m^{-1} \pmod{R}$
    y $T$ un entero tal que $0 \leq T < mR$. Si $U \equiv Tm'
    \pmod{R}$, entonces $\frac{T+Um}{R} \equiv TR^{-1} \pmod{m}$. 
  \end{teorema}
  Aquí ya se aprecia una relativamente importante tara de este método,
  y es que tan sólo podrá utilizarse cuando el módulo reductor sea
  \emph{impar}, ya que $R$ normalmente será una potencia de la base de
  trabajo, que en última instancia es $2$, y ha de cumplirse la
  coprimalidad de $m$ y $R$. Esto no suele presentar un problema en
  algoritmos como RSA, donde el módulo reductor siempre es impar, pero
  no podría utilizarse en general.

  La combinación de la reducción de Montgomery y el algoritmo
  \ref{alg:multiplicacion} de multiplicación de enteros da lugar al
  algoritmo \ref{alg:multMontgomery}, en el cual $B$ representa, como
  viene siendo habitual, la base de trabajo de la librería.

  \begin{algorithm}
    \caption{Multiplicación de Montgomery}\label{alg:multMontgomery}
    \begin{algorithmic}[1]
      \Procedure{MultMontgomery}{entero $m=(m_{n-1} \cdots m_0)_B$,
                                 entero $x=(x_{n-1} \cdots x_0)_B$,
                                 entero $y=(y_{n-1} \cdots y_0)_B$,
                                }
        \Require $0 \leq x,y < m; \quad R = B^{n}; \quad m$ impar
        \State $m' \gets -m^{-1} \bmod B$
        \State $A = (a_{n} a_{n-1} \cdots a_0)_B \gets 0$
        \For{$i=0$ hasta $i = (n-1)$}
          \State $u_i \gets (a_0 + x_iy_0)m' \bmod B$
          \State $A \gets (A + x_iy + u_im)/B$
        \EndFor
        \If{$A \geq m$}
          \State $A \gets A-m$
        \EndIf
        \State \Comment{En este punto, $A = xyR^{-1} \bmod m$}
        \State \textbf{devolver} $A$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

  Esta forma de multiplicación modular es, para una sola
  multiplicación, más costosa que multiplicar y posteriormente dividir 
  en $\mathbb{Z}$. ¿Cuál es entonces el sentido de todo esto? Que a la
  hora de realizar una potenciación modular, sí compensa utilizar este
  esquema, en base a lo que se expone en el algoritmo
  \ref{alg:potMontgomery}.

  \begin{algorithm}
    \caption{Potenciación de Montgomery}\label{alg:potMontgomery}
    \begin{algorithmic}[1]
      \Procedure{PotMontgomery}{entero $m=(m_{n-1} \cdots m_0)_B$,
                                entero $x=(x_{n-1} \cdots x_0)_B$,
                                entero $e=(e_{t} \cdots e_0)_2$
                                }
        \Require $1 \leq x < m; \quad R = B^{n}; \quad e_t = 1; \quad m$ impar
        \State $m' \gets -m^{-1} \bmod B$
        \State $\hat{x} \gets MultMontgomery(m, x, R^2 \bmod m)$
        \State $A \gets R \bmod m$
        \For{$i=t$ hasta $i = 0$}
          \State $A \gets MultMontgomery(m, A,A)$
          \If{$e_i = 1$} 
            \State $A \gets MultMontgomery(m,A,\hat{x})$ 
          \EndIf
        \EndFor
        \State $A \gets MultMontgomery(m,A,1$
        \State \Comment{En este punto, $A = x^{e} \bmod m$}
        \State \textbf{devolver} $A$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

  La ventaja computacional viene de que, aunque este método utilice el
  mismo número de multiplicaciones que la estrategia ``multiplicacion-división''
  evidente, no se realiza ninguna división, que es la operación más
  costosa de todas las operaciones básicas.
  número de multiplicaciones.

  Pero, se vuelve a insistir en ello, este método \emph{sólo} es
  susceptible de ser utilizado para módulos \emph{impares}.
    
  
  \subsubsection{Método de Barrett}
    Este método es únicamente de reducción, por lo que ha de
    combinarse con algún algoritmo de potenciación de $\mathbb{Z}$.
    Se recomienda la utilización de esta forma de reducción cuando se
    van a realizar numerosas reducciones con el mismo módulo.
    Evidentemente, la potenciación es uno de estos casos. La razón de
    tal recomendación es la necesidad del método del valor $\mu =
    \lfloor \frac{B^{2k}}{m} \rfloor$, donde $B$ es la base de trabajo
    de la librería y $m$ es el módulo reductor en cuestión. Aunque el
    coste computacional de la división es elevado, éste queda
    rapidamente compensando por el proceso de potenciación, ya que
    $\mu$ sólo ha de calcularse una única vez para cada valor de $m$. 
    
    Este método fue ideado por Paul Barrett en 1986, con el fin de
    poder implementar el algoritmo RSA en un microprocesador digital
    de señales, como se expone en \cite{barrett} (de forma además muy
    asequible). El método en cuestión se muestra en el algoritmo \ref{alg:barrett}.
 
  \begin{algorithm}
    \caption{Reducción de Barrett}\label{alg:barrett}
    \begin{algorithmic}[1]
      \Procedure{RedBarrett}{entero $x=(x_{2k-1} \cdots x_0)_B$,
                             entero $m=(m_{k-1} \cdots m_0)_B$,
                             entero $\mu = \lfloor \frac{B^{2k}}{m} \rfloor$
                            }
        \Require $m_{k-1} \neq 0$

        \State $q_1 \gets \lfloor x/B^{k-1} \rfloor$
        \State $q_2 \gets \lfloor (q_1 \times \mu)/B^{k+1} \rfloor$
        \State $r_1 \gets x \bmod B^{k+1}$
        \State $r_2 \gets q_2 \times m \bmod B^{k+1}$
        \State $r \gets r_1 - r_2$
        \If{$r < 0$} 
         \State $r \gets r + B^{k+1}$
        \EndIf
        \While{$r \geq m$} 
        \State $r \gets r -m$ 
          \Comment{\cite{handbook}\footnote{pág. %
            604, nota 14.44(ii)} nos asegura que este paso se ejecutará, %
            como mucho, dos veces}
        \EndWhile
        \State \Comment{En este punto, $r = x \bmod m$}
        \State \textbf{devolver} $r$
      \EndProcedure
    \end{algorithmic}
  \end{algorithm}

 En la implementación concreta de la librería, este método de
 reducción se intercala con el algoritmo de potenciación
 ``Izquierda-a-derecha'' descrito en \cite{knuth2}\footnote{pág. 411}
 y \cite{handbook}\footnote{pág. 615}, entre otros.

	
	 
\section{Funciones numéricas}
    Una de las características más destacadas de esta librería (no se ha
    visto nada similar en las otras librerías analizadas, véase
    \ref{libreriasSimilares}). La idea se expuso ya en la sección
    \ref{funcionesBasico}. 


      \subsection{Representación de las funciones}
      Las funciones (matemáticas) se representan mediante clases. No
      es trivial decidir qué es susceptible de ser codificado como
      clase y qué como método de otra. Por ejemplo, la implementación
      para el cálculo del
      máximo común divisor podría concebirse como un método de, por
      ejemplo, una hipotética clase \texttt{FuncionesBinarias} en vez de
      formar una clase por si misma. Ahora bien, esto deriva en
      problemas tales como que si queremos aportar nuestra propia
      implementación para el cálculo del máximo común divisor, nos
      vemos obligados a heredar de la \texttt{FuncionesBinarias} y
      redefinir el método, y el problema entonces aparece cuando
      quisiéramos redefinir la implementación de \emph{otro} de los
      métodos, por ejemplo la también binaria función para el símbolo
      de Kronecker (\ref{simboloKronecker}); 
      en tal situación, ¿se heredaría de la ya clase hija creada 
      para la redefinición del máximo común divisor? Podríamos acabar
      con una larga ristra de clases derivadas, sin saber exactamente 
      qué métodos de cada ``generación'' son propios de la librería y
      cuáles no, entre otros problemas. Siguiendo con el ejemplo de la
      función máximo común divisor, se tiene también que ¿y si se
      ofrece la versión ``extendida''(\ref{gcdExtendido}) de esta función?
      Se trabajaría entonces con más de dos argumentos en la
      implementación (habría formas de evitarlo y seguir con dos, pero
      no sería la forma más ``natural'' de trabajar. Además esto es
      sólo un ejemplo del problema más general), rompiendo la
      coherencia al tener un método con más de dos argumentos en una
      clase llamada \texttt{FuncionesBinarias}.

      Por todo ello, se construirá una clase por cada función
      o mecanismo matemático considerado, atajando así los problemas
      anteriormente citados. Pero para comprender por completo este
      esquema, resta aún analizar lo expuesto en el punto
      \ref{mecanismoDeImplementacion}
      
    \subsection{El repositorio}\label{elRepositorio}
      El esquema de funcionamiento es, a grandes rasgos, lo expuesto en
      la figura \ref{fig:funcionamientoFunciones}. En ésta se
      representa como una nube punteada lo que se ha dado en llamar el
      \index{funciones!repositorio}{\emph{repositorio de funciones}}:
      Un punto situado en un ``terreno de nadie'' por encima de la
      propia librería y del código de un hipotético usuario.
      La implementación interna de la librería utilizará este
      repositorio en todo lugar en el que necesite valerse de una
      función, incluso y especialmente en la propia implementación de
      las mismas\footnote{Así que se puede considerar a la propia
      librería como la primera ``usuaria'' de este modelo, 
      sirviendo para demostrar su validez y conveniencia.}. 
      Así, se asegura que se utilice la implementación de
      la función en esos momentos vigentes en el repositorio.

    \begin{figure}
     \begin{center}
     \includegraphics[width=1\textwidth,keepaspectratio]{funcionamientoFunciones.eps}
     \caption{Diagrama del mecanismo de funciones.\label{fig:funcionamientoFunciones}}
     \end{center}
    \end{figure}

      El usuario por su parte puede optar por valerse del repositorio
      ---el cual quizás haya él mismo personalizado ya mediante los
      métodos que se examinarán más adelante---, que sería lo
      recomendado para conservar cierta uniformidad, o valerse de sus
      propias funciones. Qué escoja dependerá de las circunstancias;
      si el usuario quiere simplemente implementar una función de las
      que la librería ofrece sin interferir en el funcionamiento de
      ésta, no personalizará el repositorio; si por contra se quiere
      estudiar el comportamiento de la implementación del usuario en
      un marco general como es todo el conjunto de la librería, se
      incorporará al repositorio esta implementación. Esto también
      posibilita la \emph{extensibilidad} de la librería por parte de
      los usuarios sin necesidad de la intervención del desarrollador,
      quien es de suponer que eventualmente acabaría incorporando
      estas versiones (supuestamente mejores) al conjunto por defecto
      del repositorio. El tiempo ``entre lanzamientos'' de versiones
      no sería pues crítico, y la curva de progreso en el software se
      acercaría idealmente al continuo, más que a un escalonamiento
      producto de estar centralizada la incorporación de nuevas
      implementaciones. Todo esto, claro está, suponiendo que la
      librería se entiende como una ``caja negra'' que no se modifica;
      es evidente que el usuario con suficientes conocimientos y/o
      tiempo podría modificar el código al igual que haría el
      desarrollador, pero esto rompería la uniformidad y podría
      degenerar en múltiples versiones de ``cajas negras''.

      Para desempeñar su función, el repositorio cuenta solamente con
      dos tipos de métodos (ver figura \ref{fig:insercionExtraccionRepositorio}),
      los destinados a la inserción (personalización) y a la obtención de las
      funciones. Para tratar de facilitar su uso, se ha establecido,
      como se puede ver en la mencionada figura, un convenio para 
      los nombres de estos métodos.

    \begin{figure}
     \begin{center}
     \includegraphics[width=1\textwidth,keepaspectratio]{insercionExtraccionRepositorio}
     \caption{Diagrama del repositorio.\label{fig:insercionExtraccionRepositorio}}
     \end{center}
    \end{figure}

  \subsection{Mecanismo de implementación} \label{mecanismoDeImplementacion}
    Al pensar en cómo satisfacer todo lo dicho hasta ahora acerca del 
    comportamiento del sistema de funciones de la librería, aparece
    el concepto de \emph{polimorfismo en tiempo de ejecución}, como se
    presenta en \cite{stroustrup}. Este concepto define precisamente
    lo que se busca; el manejo del concepto de la función matemática 
    de forma abstracta (clase base abstracta) y la resolución de las
    llamadas a métodos en tiempo de ejecución (métodos
    \texttt{virtual}).

    Así, se cuenta con un conjunto de clases base abstractas que
    definen un interfaz para cada función matemática
    soportada. Para implementar el algoritmo considerado para cada 
    una de las funciones en cuestión, se hereda de estas clases base y
    se definen al menos los métodos \texttt{virtual}, consiguiendo así
    que estos sean invocados en tiempo de ejecución y a la vez
    teniendo una especificación (la interfaz) que permite trabajar de
    forma genérica con las funciones.

    La librería incorpora su propia implementación de serie de las
    funciones soportadas (véase \ref{funcionesSoportadas}), que por
    omisión
    responderán al nombre de objeto \texttt{NombreDeFuncionDFL}. Por
    ejemplo, la implementación incorporada para el trabajo con números
    aleatorios seguros responde a la clase \texttt{RandomSeguroDFL},
    al ser la clase abstracta \texttt{RandomSeguro} la que define el
    interfaz de esta función generadora de números aleatorios seguros.
    
    En algunos casos se da más de un algoritmo para el cálculo de una
    misma cosa, y está claro que nada obliga a tener que utilizar la
    versión por omisión; siempre se podrá instanciar la clase que
    implemente el algoritmo deseado directamente, sin necesidad de
    utilizar el mecanismo del repositorio de funciones anteriormente
    descrito. Sin embargo, esto debería ser sólo necesario en aquellos
    puntos que por alguna razón requieran de una implementación
    concreta y no de la versión que en ese instante ofrezca el
    repositorio.

    
  \subsection{Funciones soportadas}\label{funcionesSoportadas}
    Se describen aquí a grandes rasgos los tipos de funciones implementadas. 
    Dado que tiene más sentido definir cada función en su contexto, aquí
    solamente se dará una pequeña definición, y la sección concreta
    de esta memoria, donde se trate más en profundidad lo relacionado
    con ella.

    Para conocer la sintaxis concreta y métodos, dirigirse al tomo del
    código fuente, en especial a la documentación de la clase
    \texttt{Funciones}.
    
%      void ponerHash(Hash* ptr);
%      void ponerPotencia(Potencia* ptr);
%      void ponerGCD(GCD* ptr);
%      void ponerGCDExt(GCDExt* ptr);
%      void ponerLCM(LCM* ptr);
%      void ponerPotModular(PotModular* ptr);
%      void ponerRedBarrett(RedBarrett* ptr);
%      void ponerRedMontgomery(RedMontgomery* ptr);
%      void ponerRedModularALaMersenne(RedModularALaMersenne* ptr);
%      void ponerSimboloKronecker(SimboloKronecker* ptr);
%      void ponerSimboloJacobi(SimboloJacobi* ptr);
%      void ponerSimboloLegendre(SimboloLegendre* ptr);
%      void ponerCRT(CRT* ptr); 
%      void ponerFactoriza(Factoriza* ptr);

    \subsubsection{Tests de \index{test!composición}{composición}}
      Esta funcionalidad es uno de los pilares básicos, ya que será
      utilizada tanto en la generación de números aleatorios seguros
      (véase \ref{randomSeguro}) como en la más evidente generación de 
      números primos. Véase \ref{testsDeComposicion} para más detalles
      y \ref{testRabinMiller} para una descripción de la implementación 
      del test incluido de serie en la librería.

    \subsubsection{Generación de números primos}
      Se proporciona una clase que engloba los métodos encargados de
      la generación de números primos, contemplándose la generación de
      los denominados \index{primos!fuertes}{``primos fuertes''}
      (sección \ref{primosFuertes}). Estos métodos devolverán números
      primos en base a un tamaño de bits especificado o a partir de
      un entero que hará las veces de cota inferior.

      Véase el capítulo \ref{cap:primos} para una descripción de los
      métodos empleados y un análisis en profundidad.

    \subsubsection{Generación de números aleatorios}
      Se brindan dos clases para la generación de bits aleatorios, que 
      son devueltos en forma de enteros. Una de estas clases genera
      números aleatorios ``seguros'', en el sentido expuesto en
      \ref{randomSeguro}, mientras que la otra ofrece datos aleatorios
      de gran calidad aunque sin tantas garantías (sección 
      \ref{generacionDeSecuenciasPseudoAleatorias}).
      Dentro del primer grupo, \ref{bbs} es la implementación por
      defecto, siendo \ref{rc4} la del segundo.

      Además, se cuenta también con la posibilidad de someter a
      cualquiera de estos generadores a una serie de pruebas
      para comprobar experimentalmente su bondad,
      \ref{testsEstadisticos}. Se implementa por omisión el método
      descrito en \ref{fips140-1}.

    \subsubsection{Funciones hash}
      Como se indica en la sección \ref{md5}, por omisión la librería implementa 
      la conocida función hash MD5. La definición de la misma y una
      implementación de referencia están disponibles en
      \cite{rfc1321}.
      
    \subsubsection{Símbolos de residuos cuadráticos}
    Se proporciona implementación para el cálculo del símbolo de
    Kronecker (sección \ref{simboloKronecker}). Como se indica en 
    \ref{residuosCuadraticos}, este símbolo engloba los de Legendre y
    Jacobi, por lo que la implementación de ambos símbolos, el de Legendre y
    el de Jacobi, realizan una llamada a la implementación del símbolo
    de Kronecker. 

    El algoritmo utilizado es el descrito en
    \cite{cohen}\footnote{pág.29, algoritmo 1.4.10}. Resulta de sumo
    interés para cualquiera interesado en la programación eficiente de
    algoritmos matemáticos (es evidente tal es el caso del autor)
    examinar el apartado ``Remarks'' de la página referenciada. A modo
    de ejemplo, se muestra a continuación uno de los malabares que
    allí se recogen:
    \paragraph{Cómo realizar la computación de 
    $k=(-1)^{\lfloor((a-1)(b-1))/4\rfloor}k$
    en $O(1)$.} A primera vista choca cuando se ve como \cite{cohen}
    realiza esta operación mediante la sentencia C \verb|if(a&b&2) k=-k|.
    Tras unos minutos (o quizás más) de reflexión, se ve la
    razón de que esto funcione, pero no deja de resultar sorprendente,
    al menos para quien, como el autor, aún se inicia en este campo. 
    Téngase en cuenta que $a$ y $b$ son impares en esa expresión, con
    $b > 0$. Pues bien, $(a-1)$ y $(b-1)$ serán entonces pares (en
    binario, su bit menos significativo será $0$). Para que $k$
    cambie de signo, el exponente de $(-1)$ ha de ser impar (que es el
    caso que \verb|if(a&b&2) k=-k| cubriría). Si consideramos la
    división entera entre $4$ como la eliminación de los dos bits
    menos significativos, tenemos que $\lfloor((a-1)(b-1))/4\rfloor$
    tendrá su bit menos significativo a $1$ (exponente impar) si y
    sólo si $a$ y $b$ tienen su segundo bit menos significativo (el
    que corresponde a $2^1$ al transformar el número desde base $2$) a
    $1$, ya que esto será lo necesario para formar la potencia $2^2$,
    ocupando la tercera posición menos significativa del producto
    $(a-1)(b-1)$. Esta tercera posición menos significativa será precisamente
    \emph{la primera menos significativa} en el momento en el que
    desplacemos tal producto dos posiciones a la derecha (esto es,
    división entera entre $4$). De ahí que sea condición necesaria y
    suficiente que $a$ y $b$ tengan su segundo bit menos significativo
    a $1$ para que $\lfloor((a-1)(b-1))/4\rfloor$ sea impar y $k$
    cambie de signo.
    
    \subsubsection{Máximo común divisor y mínimo común
    múltiplo}
      La librería implementa por omisión el algorimo de Lehmer,
      expuesto en \cite{knuth2}\footnote{pág. 329, algoritmo L} bajo
      el título ``Euclid's algorithm for large numbers'' y
      explícitamente como algoritmo de Lehmer en
      \cite{handbook}\footnote{pág. 607, algoritmo 14.57}. Este último se
      vale del algoritmo de Euclides ``clásico'' \ref{alg:euclides}.
      La versión ``extendida'' del cálculo del máximo común divisor
      (véase \ref{gcdExtendido}) se efectua mediante el denominado
      algoritmo ``binario'' para el cálculo extendido del máximo común
      divisor, como se expone en \cite{handbook}
      \footnote{pág. 608, algoritmo 14.61}. Más detalles acerca del
      máximo común divisor en la sección \ref{maximoComunDivisor}.

      Por su parte, el mínimo común múltiplo, como se apunta en la
      sección \ref{minimoComunMultiplo}, es calculado en base al
      máximo común divisor y la relación 
      $\textrm{lcm}(a,b) = \frac{|ab|}{\gcd(a,b)}$ entre ambos conceptos.


    \subsubsection{Potenciación}
    El algoritmo de potenciación por omisión elegido para $\mathbb{Z}$
    ha sido el descrito en \cite{handbook}\footnote{pág. 616
    algoritmo 14.85} y en \cite{cohen}\footnote{pág. 10, algoritmo
    1.2.4}. Es el denominado algoritmo de potenciación con ventana
    deslizante de tamaño $k$ (o, como dice \cite{cohen}, en base $2^k$).
    El cálculo del tamaño óptimo $k$ para la ventana es un tema
    interesante que se trata también en \cite{cohen}. La librería
    incorpora mecanismos de selección de este valor óptimo en función
    del tamaño del cálculo a efectuar.

    Se implementa también el más sencillo y clásico algoritmo de
    potenciación de derecha a izquierda, descrito en
    \cite{knuth2}\footnote{pág. 442, algoritmo A}, \cite{cohen}\footnote{pág. 8,
    algoritmo 1.2.1} y \cite{handbook}\footnote{pág. 614, algoritmo
    14.76}.

    Para los métodos de potenciación sobre $\mathbb{Z}_n$ considerados, véase la
    sección \ref{potEnZn}. Apuntar que el método que se considera por
    omisión es el de la combinación del método de reducción de Barrett
    y el algoritmo de potenciación en $\mathbb{Z}$ de izquierda a
    derecha, como en dicha sección se expone. La razón de esto es que
    se ha observado un incremento superior al método de Montgomery en
    las pruebas realizadas, aunque el método de Montgomery sea también
    muy eficiente.
    
    \subsubsection{Teorema Chino de los Restos}
    La implementación del algoritmo para la resolución de sistemas
    de congruencias, lo que comunmente se llama ``Teorema Chino de los
    Restos'' o CRT en sus siglas inglesas, responde al algoritmo de
    Garner, expuesto en \cite{handbook}\footnote{pág. 612, algoritmo
    14.71}. Ésta es la implementación por omisión presente en la
    librería. 

    \subsubsection{Factorización de enteros}
      Se proporcionan varios algoritmos específicos (respondiendo al
      interfaz de la clase \texttt{FactorZ}) que se aglutinan dentro
      de la clase \texttt{Factoriza} de la forma adecuada en función
      de sus características. Dichos algoritmos específicos se
      detallan en la sección \ref{factorizacion}.


