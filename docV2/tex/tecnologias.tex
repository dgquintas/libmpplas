% TECNOLOGÍAS UTILIZADAS
\chapter{Tecnologías utilizadas}\label{chap:tecnologias}

\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
          I've come up with a set of rules that describe our reactions to technologies:\\
            1. Anything that is in the world when you're born is normal and ordinary and is 
            just a natural part of the way the world works.\\
            2. Anything that's invented between when you're fifteen and thirty-five is new 
            and exciting and revolutionary and you can probably get a career in it.\\
            3. Anything invented after you're thirty-five is against the natural order of things.
        }
        \begin{flushright}
          \textbf{\textemdash Douglas Adams, The Salmon of Doubt}
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}

\bigskip



\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
          Any sufficiently advanced technology is indistinguishable from magic.
        }
        \begin{flushright}
          \textbf{\textemdash Arthur C. Clarke, "Profiles of The Future" }
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}

\bigskip

\begin{center}{\line(1,0){325}}\end{center}

%--------------------------------------------------------%



\section{OpenMP}
A la hora de seleccionar la tecnología que nos permitiera explotar el paralelismo de los sistemas
disponibles, nos encontramos básicamente con dos requisitos: el que ésta pudiera ser integrada con 
el lenguaje C++ y que estuviera orientada a sistemas de memoria compartida. Tales restricciones 
redujeron las opciones a dos, a saber: OpenMP y POSIX Threads. Ambas tecnologías en mayor o menor 
medida extendidas y probadas. Sin embargo se orientan a extremos diferentes del espectro de desarrollo. 
Mientras que PThreads --forma habitual de nombrar POSIX Threads-- requiere que la identificación de tareas, 
su asignación a unidades de ejecución y la sincronización sean realizadas de forma explícita por el programador,
el API de OpenMP abstrae al usuario de estos detalles. Por supuesto, esto resta cierta flexibilidad, pero dada la inherente
complejidad de la programación paralela, esto es más una ventaja que un problema. Por añadidura, OpenMP se orienta
al cálculo científico, mientras que PThreads tiene un alcance mucho más general; lo cual una vez más
resulta ventajoso en teoría pero contraproducente en la práctica. De hecho, OpenMP suele depender de PThreads --al
menos en sistemas UNIX-- en su implementación, la cual es dependiente del compilador. En cierto modo, OpenMP
otorga una mayor productividad al «llevar de la mano» al programador mediante su API basada en el 
modelo de programación \textit{fork/join} (\cite{openmpstandard}\footnote{sección 1.3, pág. 17}), el cual 
es de especial utilidad a la hora de abordar problemas basados en el manejo de estructuras de tipo vector;
o dicho de otra manera, datos que cuya forma más natural de ser procesados es iterativamente.
Dos características más de OpenMP que decantan definitivamente la balanza son las que \cite{parpatterns}\footnote{
apéndice A, pág. 253} denomina como \textit{equivalencia secuencial} y \textit{paralelismo incremental}.
\begin{description}
\item[Equivalencia secuencial.] Se dice que un programa es \textit{secuencialmente equivalente} cuando 
sus resultados son los mismos\footnote{concepto de igualdad sujeto a cuestiones tales como la no asociatividad
en la práctica de operaciones en punto flotante}  independientemente de si se ejecutan sobre un solo hilo --secuencialmente--
o sobre varios. Tales programas resultan más fáciles de mantener y en la mayoría de los casos de entender --y por ende de 
desarrollar--.
\item[Paralelismo incremental.] Se refiere al estilo de programación en el cual un programa evoluciona
desde una versión secuencial hasta una paralela. Progresivamente se van paralelizando ciertas porciones del método
secuencial, comenzando por aquellas más sencillas de paralelizar o cuyos beneficios al ejecutarse en paralelo serían mayores.
El paralelismo es añadido por tanto de forma \emph{incremental}. En cada etapa de este proceso, es posible verificar que
el método continúa siendo correcto, lo cual ayuda de forma inestimable durante el desarrollo, y proporciona garantías bastante
razonables de que el método paralelizado funcionará correctamente.
\end{description}
El concepto de paralelismo incremental viene como anillo al dedo a la hora de adaptar los métodos heredados de 
LibNumth.

Aunque OpenMP es una tecnología que abstrae de los detalles de implementación, es más que probable
que las implementaciones hoy disponibles se fundamenten en un enfoque SMP. Sin embargo, existen
diferencias fundamentales entre un sistema SMP y otro basado en lo denominado como \textit{Chip-scale
MultiProcessors}, CMP --tales como los sistemas multicore, tan extendidos últimamente--. Por ejemplo (\cite{landscape}),
el ancho de banda disponible entre los núcleos dentro de un mismo encapsulado es mucho mayor que la 
disponible entre procesadores en un sistema SMP. De forma análoga, la latencia es mucho menor, hasta un orden 
de magnitud, en el primer caso que en el segundo. Esto implica que \emph{no} debe pensarse en un sistema
basado en CMP como un sistema SMP, pese a que ésta es la situación actual en prácticamente todos los frentes. Las
diferentes características de los sistemas multicore brindan la oportunidad de desarrollar nuevos algoritmos que exploten
estas diferencias.

\begin{figure}[h]
\centering
\includegraphics[width=0.65\textwidth,keepaspectratio]{dilbert} 
\caption{La terminología puede a veces resultar confusa...}
\end{figure}

\section{Comprobaciones en tiempo de compilación}\label{tech:staticasserts}
  Como reza el refranero, es mejor prevenir que curar. Por tanto, mejor que simplemente detectar el error
  cuando el programa ya se encuentra en ejecución --que no es poco, pero no deja de ser una «mala cura»--, la detección
  de condiciones que no deberían darse es más efectiva cuanto antes se realice. La detección en \emph{tiempo de compilación}
  es el ideal, ya que estas comprobaciones no acarrearían un incremento en tiempo de ejecución\footnote{el tiempo de compilado
  sí es posible --incluso probable-- que aumente. Sin embargo, la compilación es un proceso puntual, frente a un número de ejecuciones
  arbitrario} y se detectarían incluso antes de que el propio programa tomase cuerpo.

  Por otra parte, no es posible comprobar más que aquellas condiciones evaluables en tiempo de compilación. Es decir,
  datos de carácter \emph{constante} y \emph{estático}. En código esto se traduce en valores declarados como \texttt{const static}, 
  o bien literales --que no dejan de ser asimismo un caso particular de éstos--.

 \subsection{Consideraciones generales}
  Un proceso de compilación se interrumpe si y sólo si el compilador se ve forzado a generar código para una expresión inválida. 
  Existen circunstancias en las cuales, incluso si la expresión a compilar es inválida, el proceso de compilación no se interrumpirá
  porque el proceso de compilado no se ve forzado en ese momento a generar instrucciones para tal sentencia inválida. El ejemplo más
  habitual es el uso de clases parametrizadas: en una clase de plantilla, sólo las funciones miembro que son utilizadas son 
  instanciadas para los tipos de la plantilla. Puede darse el caso, dependiendo del compilador, de que el código de estos métodos
  siquiera sea procesado por el compilador si no son utilizados.

  ¿Cómo forzar entonces que nuestras comprobaciones estáticas sean efectivamente evaluadas, siendo así efectivas?
  \cite{moreexceptional} responde a esta pregunta de la siguiente manera (en su discusión, \texttt{C} es una clase arbitraria):
  \begin{quote}
    The solution is to put the code that enforces the requirement into a function
    that's sure to be instantiated. The first thing most people think of is to put
    it in the constructor, because of course it's impossible to use C without
    invoking its constructor somewhere, right? True enough, but there could be
    multiple constructors and then to be safe we'd have to put the
    requirement-enforcing code into every constructor. There's a much easier
    solution, namely: \emph{Put it in the destructor}. There's only one destructor, and
    it's equally impossible to use C without invoking its destructor, so \emph{that's the
    simplest place for the requirement-enforcing code to live.}
  \end{quote}

  Los énfasis han sido añadidos. Por tanto, todo mecanismo de comprobación estática en tiempo de compilación
  se emplazará \emph{en el destructor} de la clase en cuestión.
      
  \subsection{Requiriendo métodos de un tipo de plantilla}\label{interfazSobreTemplate}
  Lo expuesto en este punto está basado en gran medida en lo expuesto en 
    \cite{moreexceptional}\footnote{item 4}. La idea es poder implementar una clase
    parametrizada sobre un tipo \texttt{T} tal que se pueda garantizar que este tipo \texttt{T}
    implemente un cierto interfaz. Pero ¿no realiza acaso esta comprobación el compilador
    sin necesidad de pasos adicionales? Sólo parcialmente.
    \cite{moreexceptional} lo expone de la siguiente forma (en su discusión, llama a la
    clase a desarrollar \texttt{C<T>}, y requiere que exista \texttt{T* T::Clone()}): 
  \begin{quote}
    It's obvious that if \texttt{C} just writes code that tries to invoke \texttt{T::Clone()}
    without parameters, then such code will fail to compile if there isn't a
    \texttt{T::Clone()} that can be called without parameters. But that's not enough to
    answer this question: Just trying to call \texttt{T::Clone()} without parameters would
    also succeed in calling a \texttt{Clone()} that has defaulted parameters and/or does
    not return a \texttt{T*}. The goal here is to specifically enforce that \texttt{T} provide a
    function that looks exactly like this: \texttt{T* T::Clone()}.
  \end{quote}

  \subsubsection{Aplicaciones}
  El poder garantizar la existencia de ciertos métodos --incluido el tipo de su valor retornado-- para un 
  tipo \texttt{T} parámetro de una plantilla tiene una aplicación inmediata en los mecanismos de categorización
  algebraica descritos en la sección \ref{categorizacionAlgebraica}: si un tipo aspira a poder considerarse
  como, por ejemplo, un grupo, habrá de contar entre otros con un método para el cálculo de la inversa de la 
  suma, que retorne exactamente un elemento también del grupo (composición interna).

  
  \subsection{Asertos estáticos}
  El concepto de \emph{aserto} como «comprobación de la certeza de algo» en el mundo de la programación
  se asocia habitualmente a comprobaciones \emph{en tiempo de ejecución}. Así, por ejemplo, en C/C++ existe el mecanismo
  estándar \texttt{assert(ex)}, que interrumpirá la \emph{ejecución} de un programa si su argumento \texttt{ex} se evalúa como falso.
  Aunque pudiera parecer que las restricciones anteriormente descritas para las comprobaciones en tiempo de compilación
  en general convierten en algo inútil el aserto estático, se expondrán en el punto \ref{aplicacionesStaticAssert} 
  escenarios en los cuales sí resulta útil.

  Previamente, se mostrará cómo se consigue este comportamiento, 
  que no forma parte de C++ de forma directa. Considérese la macro mostrada en el listado \ref{lst:staticassert}.

\begin{lstlisting}[captionpos=b,basicstyle=\footnotesize,frame=shadowbox,rulesepcolor=\color{black},language=C++,numbers=left,caption=Definición de STATIC\_ASSERT, label=lst:staticassert]
#define STATIC_ASSERT(ex) \
  do { typedef int ai[(ex) ? 1 : -1]; } while(0) 
\end{lstlisting}

  Al contrario que en el caso del estándar \texttt{assert(arg)}, no interesa devolver un valor booleano: si la expresión
  a comprobar es falsa, el proceso de compilación debe detenerse con un error. Si no lo es, continuar sin más. Idealmente,
  tampoco se generará código adicional debido a estos asertos estáticos.
  \texttt{STATIC\_ASSERT(ex)} se traduce mediante el preprocesador en una serie de sentencias un tanto particular:
  \begin{enumerate}
    \item Un bucle do-while que no itera ( \texttt{while(0)} nunca se evaluará como cierto ).\label{enum:while0}
    \item Una declaración de un alias de tipo mediante \texttt{typedef}. \label{enum:typedef}
    \item Dentro del punto anterior, una declaración de un vector estático de un tamaño $1$ ó $-1$ dependiendo
    de si \texttt{ex} resulta cierto o falso \emph{a ojos de C++}. \label{enum:elQuizStaticAssert}
  \end{enumerate}
  
  Previamente al análisis de esta construcción: cuando se pone énfasis en el valor de verdad \emph{a los ojos de C++},
  se quiere recordar al lector que, heredado del mundo de C, en C++ se evalúa como cierto todo valor distinto
  de $0$\footnote{C++ contribuyó con el tipo \texttt{bool} y sus dos valores \texttt{true} y \texttt{false} a clarificar este ámbito,
  pero siguen siendo válidos los viejos hábitos (y en este caso, necesarios)}.

  ¿Interrumpe el código anterior la compilación en función de \texttt{ex}? Sí: se consigue aprovechando la definición de 
  vector estático por parte del estándar ANSI C (\cite{c}\footnote{sección A8.6.2, pág. 239}):
  \begin{quote}
  Si la «expresión-constante» está presente, debe ser de tipo entero y con valor mayor que $0$.
  \end{quote}
  El término «expresión-constante» se refiere al tamaño que se asigna al vector estático en su 
  declaración. Así pues, por lo expuesto en el punto \ref{enum:elQuizStaticAssert} de la enumeración precedente,
  si \texttt{ex} se evalúa como falso, se estaría declarando \texttt{ai} con tamaño $-1$\footnote{¿y por qué si la
  referencia del lenguaje cita $0$ como valor ya invalido, se utiliza $-1$? Debido a que, tal como indica \cite{imperfectc++},
  por alguna razón algunos compiladores, entre ellos GCC y el compilador de Intel, sí consideran válido un vector estático de tamaño
  cero. Esto incumple claramente el estándar ANSI C, pero afortunadamente siquiera estos compiladores admiten un tamaño negativo
  como dimensión de dicho vector}, algo que incumple la semántica de C, y por tanto, también de C++. Este incumplimiento resulta
  en una interrupción de la compilación.

  La razón de ser de los puntos \ref{enum:while0}, y \ref{enum:typedef} es la de no generar código pero a la vez
  ser expresiones que son evaluadas por el compilador. Lo primero se consigue a raíz de que en realidad no existe código
  «ejecutable», ninguna sentencia con efecto sobre el entorno. Cualquier compilador que realice optimización de código (esto 
  es, todos) omitirá incluir instrucciones correspondiente a esta porción de código. Pero no antes de haberla evaluado:
  a raíz de que el bucle, al ser do-while, fuerza la entrada en su cuerpo al menos una vez. En este cuerpo, el \texttt{typedef}
  ha de evaluar el nuevo alias declarado: el vector estático en cuya dimensión reside el meollo de la cuestión.

  Véase \cite{imperfectc++}\footnote{sección 1.4.8, pág. 25} para un enfoque de este método con más profundidad.

  \subsubsection{Aplicaciones}\label{aplicacionesStaticAssert}
  Sus usos principales son los mismos que se le darían al clásico \texttt{assert} en tiempo de compilación: comprobación
  de casos que nunca deberían llegar a darse. Por ejemplo, en álgebra abstracta se requiere que el anillo que conforma
  un cuerpo cumpla una serie de propiedades: ser un anillo de división y ser conmutativo para el producto. \emph{Nunca} debería
  tenerse un cuerpo incumpliendo estas propiedades. De intentar declarar un objeto tal, el compilador debería evitarlo. Pues bien,
el código mostrado en el listado \ref{lst:staticAssertAp1} nos lo garantiza.
\begin{lstlisting}[captionpos=b,basicstyle=\footnotesize,frame=shadowbox,rulesepcolor=\color{black},language=C++,numbers=left,caption=Comprobación estática de las propiedades de un anillo, label=lst:staticAssertAp1]
~Field() {
(...)
  STATIC_ASSERT( T::divisionRing );
  STATIC_ASSERT( T::multCommutative );
(...)
}
\end{lstlisting}

Una aplicación alternativa es el forzar la evaluación de funciones estáticas, que normalmente contendrán otro tipo de 
comprobaciones en tiempo de compilación. Por ejemplo:

\begin{lstlisting}[captionpos=b,basicstyle=\footnotesize,frame=shadowbox,rulesepcolor=\color{black},language=C++,numbers=left,caption=Forzando evaluación de funciones estáticas, label=lst:staticAssertAp2]
  ~Group() {
    STATIC_ASSERT( ValidateRequirements() );
  }
(...)
private:
  static bool ValidateRequirements() {
    T (T::*getAddInverse)() const  = &(T::getAddInverse) ;
    const T& (*getAddIdentity)()  = &(T::getAddIdentity) ;
    const T& (*getGroupGenerator)()  = &(T::getGroupGenerator) ;
    return true;
  }
\end{lstlisting}

En este ejemplo --también de lo anteriormente expuesto en la sección \ref{interfazSobreTemplate}-- se requiere que \emph{el compilador}, 
evalúe las tres asignaciones del método estático \texttt{ValidateRequirements()}. Para esto, se invoca este método 
dentro del aserto estático, ya que por la propia naturaleza de éste, evaluará su contenido. Si \texttt{ValidateRequirements}
es superado con éxito, el \texttt{return true} que concluye \texttt{ValidateRequirements} evitará que se incumpla
la evaluación del aserto estático.
    

  \subsection{Vínculos de familia}\label{sec:musthavebase}
  El siguiente método, cuya función es asegurarse de que una clase dada hereda de otra, se expone en 
  \cite{imperfectc++}\footnote{sección 1.2.1, pág. 5}. Su utilidad, una vez más, deriva del hecho de ser
  una comprobación \emph{en tiempo de compilación}. Su equivalente en tiempo de \emph{ejecución} sería 
  la comprobación de que \texttt{dynamic\_cast< *Base >( instanciaDeriv )} no devuelve un valor nulo. Aún así,
  esta variante requiere una \emph{instancia} del tipo derivado, y en cualquier caso, su dominio de aplicación es 
  totalmente diferente: compilación vs. ejecución.


  Ver un ejemplo de la utilización de este patrón ayudará a explicar el funcionamiento del mismo. Considérese
  el listado \ref{lst:musthavebaseEj}. 
  \lstset{escapeinside={(*@}{@*)}}
  \begin{lstlisting}[captionpos=b,basicstyle=\footnotesize,frame=shadowbox,rulesepcolor=\color{black},language=C++,numbers=left, caption=Ejemplo de uso del patrón de verificación de paternidad, label=lst:musthavebaseEj]
Constraints::must_have_base<S, Ring<S> > dummy1; (*@\label{algparent:Ring}@*)
Constraints::must_have_base<S, MPPDataType > dummy2; (*@\label{algparent:MPPDataType}@*)
  \end{lstlisting}
  Este fragmento de código se corresponde a la clase \texttt{Polynomial<S>} (véanse las secciones \ref{tipos:polinomios} 
  y \ref{impl:polinomios} para una descripción de este tipo de dato y una pormenorización de sus detalles de 
  implementación, respectivamente). En sendas líneas se comprueba que el tipo de plantilla \texttt{S} 
  --que se corresponde al tipo de los coeficientes del polinomio-- «es un» anillo y un tipo de dato
  «de la biblioteca». \footnote{que el tipo \texttt{S} verifique las propiedades algebraicas de un anillo por el mero hecho de 
  heredar de la clase \texttt{Ring} lo aseguran los mecanismos de categorización algebraica expuestos en la
 sección \ref{categorizacionAlgebraica} --los cuales, recuérdese, se valen precisamente de mecanismos de comprobación
  en tiempo de compilación}.

  Por tanto, \texttt{must\_have\_base<TipoHijo, TipoBaseEsperado>} compilará sin problemas si efectivamente \texttt{TipoHijo} 
  hereda de \texttt{TipoBaseEsperado}. Esta relación de herencia no tiene que ser necesariamente padre-hijo: se aprecia
  en el siguiente listado de código que implementa este patrón:

  \begin{lstlisting}[captionpos=b,basicstyle=\footnotesize,frame=shadowbox,rulesepcolor=\color{black},language=C++,numbers=left, caption=Verificación de paternidad en tiempo de compilación, label=lst:musthavebase]
template<typename D, typename B>
struct must_have_base{
  ~must_have_base(){
    void(*p)(D*, B*) = constraints;
  }
  private:
  static void constraints(D* pd, B* pb){
    pb = pd;  (*@\label{algmusthavebase:quiz}@*)
  }
}; 
  \end{lstlisting}

  En la línea \ref{algmusthavebase:quiz} se encuentra el meollo del método. Si es posible realizar una conversión desde un puntero 
  del tipo derivado --\texttt{pd}-- a un puntero del tipo base --\texttt{pb}-- sin ningún tipo de \textit{cast}, \texttt{pd} resultará 
  cumplir el «ser un» elemento del tipo base. Es por esto que incluso si la relación tipo derivado-tipo base no es de herencia directa, 
  también funcionaría, al poder realizarse dicha asignación.

  
  \subsubsection{Aplicaciones}
  Su campo de aplicación fundamental son las clases parametrizadas en las cuales se desea comprobar que sus parámetros de tipo cumplen ciertas
  propiedades «familiares», tal como se ha visto para el caso del tipo de los coeficientes en polinomios. Otra de las aplicaciones dadas a
  este mecanismo en la biblioteca ha sido en la implementación del nuevo repositorio de funciones (véase sección \ref{basico:nuevoRepdeFuncs}), para
  garantizar que todo método considerado por el mismo hereda de \texttt{AbstractMethod}. Esto ahorra sorpresas desagradables en tiempo
  de ejecución si se trata de insertar u obtener una instancia de un objeto arbitrario: si se tratase de hacer esto, gracias a este mecanismo, 
  siquiera se superaría la etapa de compilación.

\section{Programación orientada a aspectos (AOP)}\label{tech:aop}
  Este relativamente novedoso paradigma es considerado por algunos como una evolución 
  del mismo modo que la orientación a objetos supuso una evolución con respecto a la programación
  meramente estructurada. 

  Se puede considerar como una forma de preprocesado avanzada. Por ejemplo, es posible especificar
  cosas como «para cada método cuyo nombre comience con ``test'', añadirlo a la lista de métodos a ejecutar
  durante las pruebas». O bien «si se está ejecutando en modo de depuración, imprimir los valores de
  los argumentos de cada método ejecutado». Todo esto sin necesidad de modificar los métodos afectados: se 
  centraliza el tratamiento de «conceptos transversales». Los «conceptos» en los dos ejemplos anteriores serían 
  los métodos cuyo nombre empieza por ``test'' y todos los métodos ejecutados, respectivamente. Asimismo, se trata
  de conceptos transversales ya que se extienden a lo largo de toda la estructura del programa.
  Como se puede apreciar, la abstracción y modularización que esta técnica ofrece son de una naturaleza diferente
  a las ofrecidas por la programación orientada a objetos. Más información acerca de este paradigma puede, entre
  otros muchos lugares, encontrarse en \url{http://www.aopworld.com/}.

  Esta tecnología ha sido utilizada para la implementación de los mecanismos de perfilado,
  como se expone en la sección \ref{impl:aop}.


\section{\textit{Mixins}} \label{tech:mixins}\index{mixin}
  En el ámbito de la programación orientada a objetos, un \textit{mixin} 
  es una clase que provee una cierta funcionalidad a sus clases hijas, con 
  la particularidad de no estar pensada para ser instanciada directamente. 
  Es en cierto modo un tipo de clase abstracta. El heredar de una clase
  mixin no se correspondería con una relación «es-un», sino 
  con una «recolección de funcionalidad».  En lenguajes que soporten herencia múltiple, 
  es posible heredar de varias clases mixin, consiguiendo
  así aglutinar las funcionalidades ofrecidas por todas ellas. 
  Si se considera un lenguaje con soporte de interfaces, tal como Java, podría pensarse que
  estos son equivalentes a las clases mixin. Sin embargo, por definición, un interfaz no lleva
  asociado una implementación, siendo su único rol el de «definir polimorfismo». 

  Este término proviene del ámbito gastronómico: al menos en el mundo de habla inglesa, 
  el término «mix-in» --que se podría traducir libremente como «parte de una mezcla»--
  se refiere a postres (típicamente helados) que se preparaban a partir
  de una serie de ingredientes en el mismo momento del encargo. Son estos ingredientes
  pensados para ser utilizados únicamente como parte de una mezcla y no por separado de donde
  el componente software toma su nombre.

  En esta librería  se ha implementado una clase siguiendo esta filosofía, que se describe a continuación. 

  \subsection{Singleton}\label{sec:singleton}
    El patrón \emph{singleton} se encuentra entre los más conocidos y ampliamente utilizados de los
    expuestos en el ya clásico \cite{gof}\footnote{pág. 127}: un objeto del cual a lo sumo debe existir 
    una instancia a lo largo de la ejecución, y que
    simultáneamente dicha instancia sea accesible globalmente. 
    
    A primera vista, su carácter global puede hacer saltar las alarmas en base a lo expuesto en el punto
    \ref{sec:thread-safety} referente a estructuras susceptibles de ser compartidas por varios hilos. 
    Claro que se ha de ir un poco más allá para determinar si realmente se incurre en un incumplimiento
    de los requisitos para ejecutarse en un entorno concurrente.

     El patrón singleton \emph{clásico} opera en general de la siguiente manera (\cite{gof}):

\lstset{escapeinside={(*@}{@*)}}
\begin{lstlisting}[captionpos=b,basicstyle=\footnotesize,frame=shadowbox,rulesepcolor=\color{black},language=C++,numbers=left,caption=Patrón singleton (I), label=lst:singleton1]
  class Singleton {
    public:
      static Singleton* instance();
    protected:
      Singleton();
    private:
      static Singleton* _instance;
  };
\end{lstlisting}

\begin{lstlisting}[captionpos=b,basicstyle=\footnotesize,frame=shadowbox,rulesepcolor=\color{black},language=C++,numbers=left,caption=Patrón singleton (II), label=lst:singleton2]
  Singleton* Singleton::_instance = 0;
  Singleton* Singleton::instance() {
    // lazy initialization!
    if(_instance == 0){ (*@\label{algsingleton:cs1}@*)
      _instance = new Singleton;
    }                   (*@\label{algsingleton:cs2}@*) 
    return _instance;
  }
\end{lstlisting}

  El detalle más importante a observar es la sección crítica (allí donde se modifica el dato estático \texttt{\_instance}), que se 
  extiende de las líneas \ref{algsingleton:cs1} a \ref{algsingleton:cs2} del listado \ref{lst:singleton2}. 
  Por tanto, en un marco concurrente, debe asegurarse la
  exclusión mutua dentro de dicha sección crítica. Esto desemboca en el uso de \textit{candados}, de tal forma que cada vez
  que se requiera acceder a la instancia en cuestión, se comprueba si no hay otro hilo ya en esa sección. Ahora bien, tras la instanciación
  inicial, la comprobación de que el punto \texttt{\_instance} no es nulo será siempre falsa, haciendo superfluas tanto dicha comprobación
  como el intento de adquirir el candado. Frente a esto se desarrolló otro patrón más complejo, bautizado como \textit{double-checked
    locking pattern} (\cite{dclp}), el cual evitaba estos problemas de una forma supuestamente thread-safe. O así se creía hasta que
  Scott Meyers y Andrei Alexandrescu desmontaron punto por punto los argumentos utilizados para garantizar esta seguridad en entornos
  concurrentes (\cite{singletonperils}). Resumiendo, quedan pues dos opciones: o se conserva el patrón singleton clásico con todas
  sus comprobaciones extras y se asume la pérdida de rendimiento «por necesidades del guión» o bien... volviendo atrás sobre nuestros pasos,
  échese otra ojeada al código del listado \ref{lst:singleton2}. ¿Qué motiva la aparición de la problemática sección crítica? El hecho 
  de estar creando la instancia singleton de forma \textit{lazy}. La justificación de --aún otro-- anglicismo aquí es debido al concepto
  de \textit{lazy initialization} (\cite{gof}\footnote{pág. 112}), que consiste en instanciar los objetos no en la fase de construcción, 
  sino solamente cuando estos son requeridos. Esto tiene interés tanto en cuanto la carga derivada de la instanciación no se aglutina 
  en el momento la construcción, sino que se distribuye a lo largo del tiempo. Si el objeto a construir es complejo, esta técnica 
  paga sus dividendos. Sin embargo, cuando esto no es así --como en el caso que nos ocupa--, resulta peor el remedio que la enfermedad. 

  De hecho, \cite{singletonperils} tiene algo que decir al respecto:
  \begin{quote}
  (...) avoid using a lazily-initialized Singleton unless you really need it. (...)
  An alternative is to use \emph{eager initialization} instead, i.e., to
  initialize a resource at the beginning of the program run. Because multithreaded
  programs typically start running as a single thread, this approach can push some
  object initializations into the single-threaded startup portion of the code, thus
  eliminating the need to worry about threading during the initialization. In many
  cases, initializing a singleton resource during single-threaded program startup
  (e.g., prior to executing main) is the simplest way to offer fast, thread-safe
  singleton access.
  \end{quote}
  Esto está en consonancia con lo expuesto en el punto \ref{par:datosStatic}. Si los objetos susceptibles de beneficiarse del patrón
  singleton pueden ser inicializados de forma estática, se estaría frente a la segunda solución, en la cual no se tiene sobrecarga
  por la comprobación superflua de condiciones, ni hay sección crítica en la que garantizar exclusión mutua: el código se simplifica
  y aún es posible dar garantías sobre su idoneidad en entornos concurrentes. La única desventaja teórica es que todas las instanciaciones
  se concentran en el tiempo. En la práctica sin embargo, para esta biblioteca, los objetos singleton son muy ligeros, con lo que esto
  tampoco supondría un problema.

    
\section{\textit{Autowiring}}\label{sec:autowiring}
    Detrás de otro vago término anglosajón, se esconde la idea de asociar dos elementos automáticamente
    en base a su tipo\footnote{en este contexto, «wiring» se refiere a la operación que antiguamente los operadores
    de las centralitas telefónicas debían realizar manualmente a la hora de establecer una conexión telefónica. 
    Podría traducirse, burdamente, como «cablear».}.
    Es más sencillo ilustrar este concepto con un ejemplo. En la figura \ref{sfig:jerarqEj}
    se presenta una sencilla jerarquía de tipos, todos implementando la clase abstracta \texttt{CommonBase}. 
    Se supone que dos de estos tipos concretos son \texttt{A} y \texttt{B}. En \ref{sfig:autowiring2}
    se presenta una colección de \emph{instancias} de tipos implementando \texttt{CommonBase}. Si 
    se combina esta colección con el uso del \textit{autowiring}, cuando a este mecanismo se le proporcionase
    un puntero a uno de las implementaciones de la jerarquía, devolvería dicho puntero asociado a la instancia
    del tipo de la colección adecuado: «cablearía» el puntero proporcionado a la instancia concreta adecuada.
 
    \begin{figure}[h] \label{fig:autowiring}
      \centering
      \subfigure[Jerarquía de ejemplo]{\label{sfig:jerarqEj}
        \includegraphics[width=0.30\textwidth,keepaspectratio]{autowiring1}
      }
      \hspace{15mm}
      \subfigure[Ilustración del \textit{autowiring}]{\label{sfig:autowiring2}
        \includegraphics[width=0.50\textwidth,keepaspectratio]{autowiring2} 
      }
      \caption{Mecanismo de \textit{autowiring}}
    \end{figure}

    La idea deriva de un mecanismo similar implementado en el popular framework para Java Spring\footnote{\url{http://static.springframework.org/spring/docs/2.5.x/reference/beans.html\#beans-factory-autowire}}.


\section{Pruebas unitarias}\label{testunits}
  Comprobar el correcto funcionamiento de cualquier programa es una tarea compleja. 
  Como el célebre Edsger W. Dijkstra apuntó en su día, 
  «Testing can only prove the presence of bugs, not their absence». 

  El concepto de \emph{prueba unitaria} nace de la idea de garantizar --al menos en parte--
  el correcto funcionamiento del todo a partir de la verificación del correcto funcionamiento
  de las partes, y que dicha verificación se realize de forma sencilla y automatizada (\cite{unittestsorig}).
  Este tipo de pruebas son el hilo conductor de \cite{testdrivendevelopment}, también de Kent Beck, y uno de los pilares
  de la filosofía de programación conocida como «extreme programming»\footnote{que no consiste
    en desarrollar mientras se salta de un avión. Se ha probado muy efectiva en numerosos ámbitos. Véase
      \url{http://www.extremeprogramming.org/} para más información.}.

  Este tipo de pruebas aportan las siguientes ventajas:

    \begin{description}
      \item[Pruebas de regresión.] En una particular variante software del 
      conocido «efecto mariposa», un pequeño cambio en una parte del código
      puede resultar en nuevos bugs en otras partes del código que a primera
      vista pudiera parecer independiente. Si se mantiene la disciplina
      de ejecutar \emph{íntegramente} la batería de pruebas con cierta regularidad, es posible
      verificar que cambios recientes no han introducido nuevos errores en código ya
      probado. 
      \item[Son ejemplos prácticos.] El código que conforma la prueba en sí es un ejemplo práctico de utilización
      de la biblioteca. 
      \item[Facilitan la identificación de errores.] Ya que los casos de prueba abarcan por construcción
      un único método, en el momento en el que uno de ellos falle, resulta sencillo identificar de 
      dónde se deriva el error.
      \item[Facilitan los cambios.] Dado que es sencillo verificar si cada una de las piezas sigue
      funcionando correctamente, se incentiva el realizar cambios para mejorar el código.
    \end{description}

  La implementación de los mecanismos necesarios para llevar a cabo
  los procesos de pruebas automáticos anteriormente descritos, aunque sencillos,
  no han sido desarrollados de nuevo, sino que se ha utilizado el paquete QtUnit, de forma totalmente satisfactoria. 

  \subsection{Necesidad y uso de un «oráculo»}\label{tech:oraculo}
    Es en general prácticamente imposible cubrir todo el espectro de valores
   de entrada y salida válidos e/o inválidos para un método dado. 
   Se suele paliar esta limitación utilizando valores «de frontera», 
   aquellos que se encuentran en el límite de los valores de entrada válidos,
   para los cuales --en teoría-- es posible que se produzca una respuesta incorrecta 
   con mayor probabilidad. 

   Sin embargo, para una biblioteca como la que nos ocupa, esto dista aún mucho de cubrir 
   una parte representativa de sus datos de entrada: más aún cuando el dominio válido para
   gran cantidad de métodos es potencialmente infinito, lo cual es precisamente
   la utilidad de la biblioteca: la precisión arbitrariamente grande de los datos manejados.
   Ante lo limitado de considerar una serie de pares entrada/salida, generados de antemano
   de tal forma que se garantiza su corrección, se ha optado por recurrir a un \emph{oráculo}\index{oráculo}. 
   En otros ámbitos, tales como la criptografía o la teoría de la complejidad,
   se utiliza también este término de manera similar. La idea es disponer de una «caja negra»
   de la cual pueden extraerse respuestas que, por definición, se consideran correctas.
   Si se dispone de un oráculo tal, capaz de proporcionar una respuesta para el par método-entradas,
   sería posible automatizar aún más la ejecución de pruebas con un conjunto de entradas mucho mayor,
   al poder generarse las entradas de forma aleatoria. Estas entradas serían 
   procesadas por el método en cuestión de la biblioteca y su equivalente en el oráculo. Si las 
   respuestas coinciden, se considera superada la prueba.

   El único escollo de esta técnica en la práctica es la necesidad de adaptar las entradas y salidas
   al formato propio del oráculo. Y por supuesto, que un oráculo como el descrito
   exista. En el caso de la biblioteca, se ha recurrido al uso de otra biblioteca de similares funcionalidades
   --aunque de filosofía de trabajo totalmente diferente--: el sistema Pari/GP, \cite{libpari}. Se asume que tras
   todos los años de desarrollo y pruebas\footnote{la versión más antigua a la que se ha podido tener acceso 
     data de $1991$ }, se puede considerar que cumple los requisitos para ser considerado como oráculo.
   La adaptación de los datos de entrada y salida anteriormente referida no resulta complicada para el sistema 
   Pari/GP: al igual que la biblioteca desarrollada, cuenta con mecanismos para transformar desde (y hacia) cadenas de caracteres.



\section{\textit{Mock/stub objects}}
El concepto de \textit{mock object}\footnote{podría traducirse como «objeto simulado», aunque incluso en la
  bibliografía en castellano se utiliza la expresión en inglés} se introduce en \cite{testdrivendevelopment}\footnote{capítulo 27}
  como un patrón útil dentro de las
  baterías de pruebas
  basadas en pruebas unitarias (véase sección \ref{testunits}). 

  En el caso de esta biblioteca resulta ventajosa la utilización de estos objetos en lo relacionado con las rutinas 
  ofrecidas por el entorno OpenMP. Sin embargo, estas rutinas  --descritas en \cite{openmpstandard}\footnote{capítulo 3, pág. 97}--
  no se encuentran disponibles si se compila la biblioteca con un compilador que no soporte OpenMP o bien si dicho 
  soporte se encuentra desactivado\footnote{una de las razones para prescindir de OpenMP aun cuando el compilador
  lo soporte sería que el sistema no contase más que con una unidad de ejecución. En tal caso, el utilizar
  OpenMP no aportaría ventajas y sí el inconveniente de la sobrecarga que acarrea su uso.}. ¿Qué hacer entonces 
  en aquellas partes del código donde se depende de estas rutinas? La solución trivial sería, previamente a su uso,
  comprobar si el soporte para OpenMP está disponible. Sin embargo, el mantener un código tal resulta muy engorroso 
  y, desde un punto de vista estético, muy poco elegante. 

  El punto clave hacia una mejor solución estriba en darse cuenta de que es posible \emph{imitar} el comportamiento
  de dichas rutinas cuando o bien el sistema no las soporta o se encuentran desactivadas: su comportamiento
  se correspondería a la situación en la que OpenMP sí estuviera disponible y el máximo número de hilos disponibles en
  todo momento fuera uno. De esta manera, cuando OpenMP se encontrase disponible, las llamadas a estas rutinas se 
  ejecutarían de forma «nativa». En caso contrario, serían sus «imitadoras» las que serían ejecutadas. Todo ello de forma
  transparente para el código que recurriese a las mismas.

  Esta idea no es nueva. Incluso \cite{openmpstandard} en su apéndice B provee una base para la implementación de estas
  rutinas sustitutas.

  
 \section{Generación dinámica de código}
  La clave de la flexibilidad reside en el dinamismo. Dicho con menos pompa, para encajar 
  en muchos sitios, se debe de poder cambiar con facilidad. Esto, unido a la idea de «que trabaje la máquina»
  lleva a desarrollar mecanismos que, en función del entorno, introduzcan los cambios necesarios para
  adaptarse a las peculiaridades de éste. Evolución instantánea y a la carta. 

  La implementación de estos mecanismos suele requerir un uso poco ortodoxo o directamente 
  chocante de las herramientas al uso. Tanto más en cuanto C++ no se presta por su naturaleza a este
  tipo de operaciones, lo que hace necesario recurrir a instrumentos alternativos que complementen
  al lenguaje. 

  \subsection{Herramientas de soporte}
    Debido a que C++ no posee mecanismos orientados a la introspección ni a la ejecución dinámica de código,
    es necesario recurrir a otras herramientas para conseguir el mismo efecto. O bien utilizar técnicas
    como la metaprogramación de plantillas (\textit{template metaprogramming}) para conseguir un efecto similar. 

    Una descripción de los elementos generados dinámicamente se da en \ref{desc:dynamic}, mientras
    que la implementación se expone en la sección \ref{impl:dynamic}.
    \paragraph{Python.} Utilizado a modo de «preprocesador» extra a la hora de recopilar información durante
    el proceso de compilado y generar ciertas porciones de código, tal como las utilizadas en las clases
    \texttt{SystemInfo} y \texttt{CPUInfo}. 
    \paragraph{AspectC++.} Herramienta utilizada para incorporar mecanismos propios de la programación orientada
    a aspectos (AOP) en C++. Utilizada en la implementación del perfilado, se describe en \cite{aspectc++}. Para
    información sobre el uso que se le ha dado en la biblioteca, véase la sección \ref{tech:aop}.
    \paragraph{Metaprogramación de plantillas.} Posiblemente lejos de ser el uso para el que fueron diseñadas, 
    las plantillas de C++ hacen posible realizar verdaderos malabarismos. Debido a esta potencia, 
    es también uno de los mecanismos más complejos y que más sorpresas, para bien o para mal, 
    da al programador. 
    
    En la biblioteca se utiliza para realizar el cálculo de una constante en tiempo de compilación. Véase la sección \ref{impl:templatemp}.
    En \cite{c++templates} dedican su capítulo $17$ a esta técnica. 



\section{Para el desarrollo}
  
   El presente proyecto cuenta aproximadamente con $32000$ líneas
de código, repartidas en aproximadamente $150$ ficheros. Gestionar toda esta cantidad de datos de forma
manual habría resultado tedioso y propenso a errores al punto de haber tenido que emplear un elevado porcentaje
del tiempo de desarrollo en el manejo del propio trabajo creado. Este sería un trabajo «de sobrecarga», sin un
resultado útil. De nuevo, ¡qué trabaje la máquina! Por ello, a lo largo del proceso de desarrollo se ha recurrido a
herramientas de uso habitual en proyectos de cierta envergadura.

  \subsection{Control de versiones}\label{tech:svn}
    En el momento de escribir estas líneas, a falta de no demasiados cambios, se han 
    realizado aproximadamente $700$ revisiones al código. Puede pensarse en estas revisiones como
    cada una de las mini-versiones que acaban desembocando en un producto final o una versión considerada
    apta para su publicación. Estas revisiones han sido gestionadas mediante el uso del sistema de control
    de versiones Subversion, \url{http://subversion.tigris.org/}\footnote{y es posible
    examinar el historial íntegro de las mismas para esta biblioteca en \url{http://fisheye3.cenqua.com/browse/libmpplas}}.

    Este tipo de sistemas de control de versiones despliegan toda su potencia en entornos de desarrollo
    colaborativos, donde varios desarrolladores contribuyen a una pieza de software común. Pero incluso cuando se cuenta
    con un único desarrollador como en este caso, resulta ventajoso tanto en cuanto se han utilizado varios sistemas
    para desarrollar. La existencia de «un tercero» que haga las veces de árbitro en el versionado facilita la sincronización
    y --sobre todo-- el seguimiento de los cambios. No es desdeñable tampoco la capacidad de deshacer cambios, volviendo
    hacia una versión anterior de un fichero determinado o del conjunto total de la biblioteca. 

    El mundo de los sistemas de control de versiones, como Subversion, CVS, GIT, etc., es ámplio y complejo, y no se
    profundizará más aquí sobre el mismo. Resulta sin embargo un elemento «\textit{sine qua non}» en cualquier proyecto
    real.

  \subsection{Gestión de la compilación}\label{tech:scons}
    Si la gestión de las versiones resulta una carga pesada cuando se trabaja con las cifras presentadas
    anteriormente, no menos fastidioso resulta su compilación. Si además se desea soportar diversos «sabores»
    en la compilación, resultando en una biblioteca compilada con diferentes opciones activadas o no, no es ya
    una cuestión de preferencia, sino de necesidad, el utilizar alguna herramienta que lleve las riendas del proceso
    de compilación en base a las opciones dadas por el usuario.

    Tal herramienta ha sido en este caso SCons, \url{http://www.scons.org/}. Lo sencillo de su uso unido a la potencia
    que proporciona ha sido la razón para elegirla por encima de métodos más tradicionales como Make.


    \subsubsection{Autoajuste al entorno}
      Cada sistema tiene sus particularidades, y es deseable poder adaptarse a ellas con el fin de contar con un producto,
      en este caso la biblioteca, lo más flexible posible. Algunos de los parámetros del entorno son tomados en consideración
      en tiempo de ejecución, mientras que otros lo son al compilar. Es de estos últimos de los que se ocupará este punto. 

      \paragraph{Verificando el entorno.} El código desarrollado descansa sobre algunas suposiciones. Se ha
        minimizado este conjunto de asunciones, pero no es posible eliminarlo por completo. En concreto, se
        require la existencia de dos tipos por parte de la biblioteca de C instalada en el sistema: \texttt{uint32\_t}
        y \texttt{int32\_t} para arquitecturas de $32$ bits; \texttt{uint64\_t}y \texttt{int64\_t} para arquitecturas de 
        $64$ bits. Estos se corresponden con tipos sin y con signo respectivamente, de la longitud en bits indicada. 
        No son tipos estándar según ANSI C o C++, pero se recogen dentro de la nueva revisión del estándar C, \cite{c99},
        en su sección 7.18.1.1. 
        
        SCons verifica el soporte de estos tipos por parte del compilador, abortando la compilación en caso de
        no estar presentes.
        
      \paragraph{Adaptándose al sistema.}
        Es posible invocar a SCons suminitrándole manualmente valores para una serie de variables
        de compilación --véase la sección \ref{desc:scons} para una descripción de estas opciones--.
        Si para alguna de estas variables no se especifica valor, o incluso si se especifica pero
        debe verificarse si el valor dado tiene sentido para el hardware subyacente, es necesario
        examinar el soporte presente en el sistema. Las opciones cuyo valor adecuado SCons se ocupa 
        de detectar incluyen:
        \begin{description}
          \item[Arquitectura.] SCons detecta automáticamente qué arquitecturas soporta el
          hardware subyacente. Algunos sistemas soportan más de una arquitectura. En concreto, los sistemas
          x86-64 soportan asimismo la arquitectura x86 de $32$ bits. En este caso, se toma la arquitectura 
          más ventajosa en términos de rendimiento.
          \item[Instrucciones SIMD.] La biblioteca soporta dos conjuntos de instrucciones SIMD, las SSE y SSE2
          de Intel. SCons autodetecta si está presente soporte para alguno o ambos de estos conjuntos de
          instrucciones.
          \item[Soporte de OpenMP.] Algunos compiladores, como el de Intel, soportan OpenMP desde hace tiempo.
          Sin embargo, GCC incluye este soporte solamente a partir de su versión 4.2. Detectar este soporte
          permite proporcionar los parámetros adecuados al compilador en cuestión.
        \end{description}

    %TODO: completar?



