% CAPITULO DE INTRODUCCIÓN

\chapter{Introducción}

\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
          Todo comienzo tiene su encanto.
        }
        \begin{flushright}
          \textbf{\textemdash Johann Wolfgang von Goethe  }
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}

\bigskip

\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
          The Feynman Problem-Solving Algorithm: \\
          (1) write down the problem; \\
          (2) think very hard; \\
          (3) write down the answer.
        }
        \begin{flushright}
          \textbf{\textemdash Atribuida a Murray Gell-Mann}
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}


\begin{center}{\line(1,0){325}}\end{center}

%--------------------------------------------------------%
  
  El presente Proyecto Fin de Carrera descansa sobre las bases establecidas por otro trabajo
  similar, aunque más modesto, realizado también como Proyecto Final de Carrera de la Ingeniería 
  Técnica en Informática de Sistemas. Éste, \cite{miproyecto}, fue realizado también por 
  quien suscribe, David García Quintas. La dirección también repite, de mano de
  Policarpo Abascal Fuentes y Jorge Jiménez Meana. El haber podido volver a trabajar
  con ellos, sobre el mismo campo en más profundidad así como en otros nuevos, ha sido una suerte,
  y con el presente trabajo aspiramos no sólo a completar el anterior Proyecto, sino a utilizar éste
  como referente y punto de partida para de esta forma poder desarrollar nuestras ideas sabiéndonos
  conocedores --y creadores-- del total del trabajo.

  Esta base, la biblioteca LibNumTh, ha sido modificada en numerosos puntos, llegando a fundirse
  indistinguiblemente con las mejoras y novedades. El resultado es el presente trabajo, bautizado
  como LibMPPLAS. A lo largo de esta introducción se pormenorizarán estas mejoras y novedades.



\section{Motivación}
  Insistir en la implementación de una biblioteca cuyos métodos, desde la distancia, 
  parecen ya cubiertos por numerosas soluciones, tanto libres como comerciales, puede parecer
  superfluo: MatLab, Mathematica, GMP, Pari... muchos de estos paquetes cubren varios aspectos
  de los soportados por esta biblioteca. Sin embargo, exceptuando quizás a Mathematica, no cubren
  simultáneamente todo el espectro de funcionalidades de la biblioteca. O bien su forma de trabajar
  no resulta, a nuestro juicio, tan cómoda\footnote{un ejemplo es el trabajo con cuerpos finitos,
  descritos en la sección \ref{cuerposFinitos}}.


  La característica «estrella» de la biblioteca es el incorporar el tan en boga concepto
  de \emph{paralelismo}. Con la relativamente reciente incorporación de múltiples unidades de ejecución
  --núcleos-- a los procesadores de consumo, se hace necesaria en la industria una revisión drástica de
  los métodos hasta ahora existentes, fundamentalmente orientados a un trabajo secuencial. Se expone
  a continuación una justificación del interés por este campo, así como un pequeño análisis de la situación
  del mismo. Se remite al lector a \cite{landscape} para más detalles.

  \subsection{A rey muerto, rey puesto.} La variante de la manida «Ley» de Moore, la cual mantiene que 
  el rendimiento de los procesadores se duplicaba cada dos años\footnote{varios apuntes: es obvio que 
  se trata de una \emph{observación}, no una «ley» en el sentido científico del término. Sin embargo se
    mantiene este último término por encontrarse ampliamente extendido. Por otra parte, lo dicho
    por Moore en \cite{moore} se refiere no al \emph{rendimiento}, sino al \emph{número de transistores}
  por circuito integrado. El salto a rendimiento se da en base a que a mayor número de transistores, mayor 
    rendimiento. Sin embargo, no tiene por qué cumplirse de forma lineal.}
  no se mantiene por más tiempo. En la figura \ref{fig:perfGraph}
  se muestra la progresión del rendimiento \emph{general} de uniprocesadores de $1978$ hasta $2006$. 
  De $1986$ hasta $2002$, se mantuvo una tendencia de incremento anual del $52 \%$. Sin embargo, del $2002$ al
  $2006$ este incremento se redujo por debajo del $20 \%$, al punto de representar en $2006$ un rendimiento
  tres veces menor del esperado de haberse mantenido la anterior tendencia. Las principales causas se resumen en:
  \begin{description}
  \item[La barrera energética] (\textit{Power wall}) Se ha pasado de considerar al precio de transistores como
  factor limitante, mientras la energía consumida por estos no tenía importancia, a la situación inversa: alimentar
  y sobre todo \emph{refrigerar} centros de cálculo es considerablemente más caro que la inversión en equipos. En muchas
  ocasiones resulta incluso imposible ampliar este tipo de instalaciones no ya por falta de espacio, sino por la imposibilidad
  física de disipar todo el calor residual generado por los equipos.
  \item[La barrera de la memoria] (\textit{Memory wall}) Mientras que 
  \item[La barrera a nivel de instrucciones] (\textit{ILP\footnote{Instruction Level Parallelism} wall}) En los últimos 
  años tecnologías tales como la ejecución fuera de orden, la predicción de saltos, la ejecución especulativa de instrucciones, etc.
  han sido las responsables de haber ayudado a seguir cumpliendo la Ley de Moore. Sin embargo la innovación en estos campos
  parece estar en declive.
  \end{description}

  \begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth,keepaspectratio]{perfGraph} 
    \caption{Rendimiento integer SPEC vs tiempo. (Figura 2 en \cite{landscape})}\label{fig:perfGraph}
  \end{figure}

  La introducción del paralelismo en la computación de propósito general no parece responder a un interés por parte
  de la industria o los consumidores --ya que por otra parte, la computación paralela lleva muchos años siendo
  utilizada en ámbitos especializados--, sino más bien a la única salida que los fabricantes tienen de 
  aspirar a mantenerse dentro de los parametros de aumento del rendimiento cada cierto tiempo. 
  Algo que reafirma cómo
  la industria se esfuerza por hacer que la observación de Moore se cumpla, y no al revés. Se juega también con el
  hecho de que la formulación original de Moore, referente al número de transistores, se cumple más facilmente:
  efectivamente el integrar un mayor número de núcleos en un único encapsulado implica el uso de más transistores. El que
  esto se traduzca en un incremento lineal --o próximo a éste-- dependerá ya del nivel de paralelización de la arquitectura, software
  del sistema y programas de usuario subyacentes, no ya sólo del hardware.
 
  Dado que el numero método de incremento del rendimiento pasa a ser la explotación del paralelismo en vez de una mayor
  frecuencia de reloj, cualquier mejora obtenida fruto de la paralelización debe tenerse muy en cuenta. 
  En la línea del refrán que encabeza este punto, el rey basado en el aumento
  de la frecuencia de reloj o la microarquitectura monoprocesador ha muerto. Se
  da paso presto al nuevo rey del paralelismo. Y al igual que en las situaciones históricas donde realmente se instauraba
  un nuevo monarca, es momento propicio para cambios (\cite{landscape}, conclusiones):
    \begin{quote}
    From a research perspective, however, this is an exciting opportunity. Virtually any
    change can be justified --new programming languages, new instruction set architectures,
    new interconnection protocols, and so on--.
    \end{quote}


  \bigskip

  Un apunte curioso para finalizar: Seth Lloyd analiza en un interesante artículo (\cite{ultimatelimits})
  los límites físicos de la computación, determinados por la velocidad de la luz $c$, la constante
  de gravitación universal $G$ y la constante reducida de Plank $\hbar$ en el marco definitivo de la computación cuántica. 
  Entre otras interesantes conclusiones está como, si se considera un ordenador de $1$ kg. y $1$ litro de volumen, 
  el número máximo --limite \emph{físico}-- de operaciones resulta ser de $5.4258 \times 10^{50}$, con una máxima capacidad
  de almacenamiento de $\approx 10^{31}$ bits --es decir, $1.25$ millones de yottabytes, $1250$ billones de petabyes.
  A la vista de estas cifras concluye que si la variante de la Ley de Moore relativa al rendimiento se mantuviese, 
  se tardaría «solamente» $250$ años en compensar los $40$ ordenes de magnitud que separan los ordenadores actuales de
  esos máximos teoricos. Parece un cierto indicador de que la Lay de Moore tiene los días contados.
  



  \subsection{Características a destacar}

  Pero no sólo es el uso de paralelismo lo que caracteriza a esta biblioteca. Varias tecnologías y enfoques
  novedosos han sido aplicados también: comprobaciones en tiempo de compilación para asegurar la coherencia
  algebraica de los tipos, el reciente paradigma de la «programación orientada a aspectos» (AOP), \textit{mock
    objects} que suplantan funcionalidades cuando éstas no se encuentran disponibles para homogeneizar el código,
   patrones de diseño tales como los \textit{mix-ins}, etc. Los pormenores de las tecnologías utilizadas se exponen
   en el capítulo \ref{chap:tecnologias}.
   Aún con el afán de investigar enfoques útiles a la vez que originales, incluso en los programas de ejemplo desarrollados
   se han utilizado técnicas como la autoescritura e interpretación en tiempo de ejecución de código y computación distribuida
   mediante XML-RPC. Puntualizando de forma resumida:


    \begin{itemize}
    \item Comprobaciones estáticas en tiempo de compilación. Utilizadas por ejemplo para asegurar
          la coherencia matemática en los tipos de datos. Ver \ref{tech:staticasserts}.

    \end{itemize}

   Resumiendo: es no sólo el interés por desarrollar un abanico relativamente amplio de métodos con los cuales resulte 
   cómodo trabajar --cuyo rendimiento no sea puntero pero sí competitivo--, sino también explorar nuevas técnicas y su aplicación
   práctica a problemas concretos. Es mediante esta experimentación original mediante la cual modestamente se espera 
   contribuir al eventual progreso de la computación científica.  


\section{Objetivos}
%%TODO: completar 
%\begin{itemize}
%  \item Números enteros, $\mathbb{Z}$
%  \begin{itemize}
%    \item Enteros de longitud arbitraria.
%    \item Aritmética general.
%    \item Generación de números aleatorios.
%    \item Orientadas hacia la Teoría de Números.
%    \begin{itemize}
%      \item Símbolos para Residuos Cuadráticos
%      (Legendre-Jacobi-Kronecker).
%      \item Rutinas para el cálculo del Máximo Común Divisor (GCD).
%      \item Rutinas para el cálculo del Mínimo Común Múltiplo (LCM).
%      \item Pruebas de primalidad.
%      \item Generación de primos.
%      \item Algoritmos de factorización.
%      \item Algoritmos de potenciación.
%      \item Teorema Chino de los Restos (CRT).
%    \end{itemize}
%    \item Aritmética modular, $\mathbb{Z}_n$
%    \begin{itemize}
%      \item Potenciación modular.
%      \item Métodos especiales de reducción. 
%      \item Cálculo de inversas.
%      \item Cuerpos Finitos $\mathbb{F}_p$.
%    \end{itemize}
%  \end{itemize}
%  
%  \item Conjunto $\mathbb{R}$
%  \begin{itemize}
%      \item Operaciones aritméticas habituales sobre $\mathbb{R}$.
%      \item Precisión (decimal) arbitraria.
%      \item Técnicas para un redondeo correcto.
%      \item Soporte de notación científica.
%      \item Algoritmos de potenciación.
%  \end{itemize}
%
%  \item Mecanismo de excepciones para el tratamiento de errores.
%
%  \item Arquitectura de "plug-ins" que posibilita que el usuario dé su
%    propia implementación de las funciones para ser ésta la utilizada en
%    todos los demás algoritmos de forma transparente y sin
%    recompilación.
%
%  \item Mecanismos de perfilado integrados en la propia librería.
%
%\end{itemize}



\section{El sistema de desarrollo}\label{sistemaDeDesarrollo}
  \subsection{Sistemas hardware}
  \begin{description}
    \item[Intel Core 2 Duo E6750 CPU] 
      Sistema multinúcleo en el que se han ejecutado las pruebas en paralelo. 
      %TODO: completar
    \item[Intel Pentium M Banias B1 CPU] 
      Sistema monoprocesador y principal plataforma de desarrollo. 
      %TODO: completar
  \end{description}

  \subsection{Sistemas software}
  \begin{description}
    \item[Sistema operativo Linux.]
      En su versión 2.6.x. Ha sido el sistema operativo
      principal en el desarrollo. Los distintos programas y versiones
      de bibliotecas fundamentales del sistema han sido:
      \begin{description}
        \item[Bibliotecas del sistema.] 
          Implementación GNU de la biblioteca de C, versión 2.5.
        \item[Compiladores.]
        \begin{description}
          \item[GCC] Compilador GNU Compiler Collection, en dos diferentes variedades: con soporte
          OpenMP (versión especial de RedHat 4.1.1 con el soporte OpenMP de la versión 4.2) y sin él
          (versión oficial 4.1.2). 
          \item[Intel Compiler] En su versión 9.1. Soporta OpenMP.
        \end{description}
        \item[Documentación.]
          Procesador de documentos \LaTeXe{} y \TeX{} versión 3.141592
          \footnote{un inciso curioso: las versiones de \TeX{} se numeran de
          forma convergente al valor de $\pi$} para la presente
          documentación.
          Procesador Doxygen versión 1.5.1 para el procesador de la
          documentación del código.
        \item[Edición.]
        \begin{itemize}
          \item Editor VIM versión 7.0 para la escritura del código y la documentación. 
          No se ha utilizado ningún tipo de entorno para la creación del código.
          \item Editor de diagramas Dia versión 0.96.1 para la creación de los
          diagramas presentes en la documentación.
        \end{itemize}
        \item[Software adicional.]
          Python 2.5
          %TODO: completar
      \end{description}
      
    \item[Sistema operativo Windows.]
    %TODO
    \end{description}
      
