\chapter{Paralelismo en la biblioteca}

\begin{flushright}
  \begin{minipage}[t]{13cm}
    \begin{flushright}
      \begin{quote}
        \emph{
          Right now I'm having amnesia and déjà vu at the same time.
        }
        \begin{flushright}
          \textbf{\textemdash Stephen Wright siendo paralelo.}
        \end{flushright}
      \end{quote}
    \end{flushright}
  \end{minipage}
\end{flushright}

\bigskip

\begin{center}{\line(1,0){325}}\end{center}

%--------------------------------------------------------%

\section{Introducción}

  Se ha hecho énfasis en la paralelización de los métodos básicos sobre los 
  que la mayoría de las rutinas de más alto nivel se apoyan. Por varios motivos:
  \begin{description}
    \item[Por su propia naturaleza.] Como métodos \emph{básicos}, son utilizados con 
    mucha mayor frecuencia, y por un abanico mayor de clientes. Cualquier optimización
    --en este caso la paralelización-- tendrá un efecto beneficioso directamente proporcional 
    dichos factores.
    \item[Facilidad.] La complejidad de los métodos suele ser mayor en métodos de más alto nivel.
    Por ejemplo, compárese la complejidad de los métodos de factorización de enteros con la implementación
    básica del producto de enteros. Es incluso probable que la adaptación paralela de los actuales 
    métodos secuenciales no sea posible sin una reescritura completa del método. Nótese sin embargo como,
    en base al punto anterior, incluso los complejos métodos no paralelizables sí se benefician de la paralelización
    de los básicos: siguiendo con el ejemplo de la factorización y el producto de enteros, el primer método sí se valdrá
    del segundo y será \emph{parcialmente} paralelo de forma indirecta.
    \item[Modularidad.] Un método básico es susceptible de ser reutilizado en algún otro lugar, haciendo gala de su
    modularidad. Consigo arrastrará su condición de paralelo, haciendo extensiva esta característica incluso allí 
    donde no se ha hecho un esfuerzo explícito en este sentido. 
  \end{description}


\subsection{Terminología}
  \begin{description}
  \item[Tarea.] Unidad básica en el particionado paralelo de un problema. En \cite{parpatterns} se
  define como:
  \begin{quote}
    (...) a sequence of instructions that operate together as a group.
    This group corresponds to some logical part of an algorithm or program.
  \end{quote}.

  \item[Unidad de ejecución.] Una \emph{tarea} debe ser asignada a una \emph{unidad de ejecución} con 
  el fin de ser completada. Desde el punto de vista de esta biblioteca se hablará \emph{hilos}. Se
  define por tanto este concepto como una serie de entidades lógicas --\emph{hilos}-- 
  susceptibles de ejecutarse de forma concurrente.

  \item[Procesador o CPU.] Se refiere al elemento \emph{físico}, esto es, \textit{hardware}, encargado de
  procesar las instrucciones proporcionadas por el usuario. Su estructura internal --\emph{lógica}-- puede variar 
  considerablemente, conteniendo una o varias \emph{unidades de procesamiento}.

  \item[Unidad de procesamiento.] Término generico para cualquier elemento hardware capaz de ejecutar una
  secuencia de instrucciones. El elemento hardware concreto depende del contexto, pudiendo variar desde un
  núcleo en un procesador multinúcleo a toda el procesador en su conjunto. 
  \end{description}

  \subsubsection{Especificación del paralelismo}
    Desgraciadamente, no existe una sintaxis universalmente aceptada para la especificación
    de algoritmos paralelos. No será en esta memoria donde se contribuya a empeorar aún más esta
    situación, sino que nos ceñiremos a la sintaxis del la tecnología utilizada para la obtención
    de paralelismo en nuestros métodos, OpenMP. Esto conlleva que el lector habrá de estar al menos
    parcialmente familiarizado con la sintaxis de este interfaz. Afortunadamente, no se trata de una
    familia de métodos bastante reducida y de fácil interpretación. Para una introducción de apenas
    veinte páginas --pero ya suficiente para la comprensión del código aquí incluido--, véase 
    el apéndice A de \cite{parpatterns}. En cualquier caso, en la opinión del autor, la mayoría de 
    los ejemplos de código son autoexplicativos aun utilizando las directivas de OpenMP.


\subsection{Arquitecturas paralelas}
  A lo largo de los años, se han desarrollado numerosos enfoques 
  de cara al proceso en paralelo. Se hace necesario el «cartografiar» 
  este dominio, algo que M. J. Flynn realiza ya en $1972$:
   \paragraph{La taxonomía de Flynn}\label{flynn}
    Como se indica en \cite{parpatterns, sourcebook}\footnote{sección 2.2.1, pág. 8; sección 2.2, pág. 26 resp.}, 
    esta clasificación es con un amplio margen la más extendida. Se realiza
    en base al número de sequencias\footnote{\textit{streams}} de instrucciones y de datos.
    Se distinguen las cuatro categorías mostradas en la siguiente tabla:
    \begin{center}
    \begin{tabular}{|c||c|c|} \hline \label{tab:flynn}
      & \textbf{Instrucción única} & \textbf{Instrucción múltiple} \\
        \hline \hline
        \textbf{Dato único} & SISD & MISD \\
        \hline
        \textbf{Dato múltiple} & SIMD & MIMD \\ \hline
    \end{tabular}
    \end{center}

    En detalle:

    \begin{description}
    \item[SISD] (Single Instruction Single Data). El enfoque «clásico», cuyo exponente es la máquina de von Neumann. Una
    única secuencia de instrucciones procesa una única secuencia de datos. Obviando detalles tales como arquitecturas 
    superescaleres, éste es el modelo de la mayoría de los procesadorse de consumo hasta aproximadamente $1997$, cuando
    Intel introduce la tecnología MMX (\cite{intelVol1}, capítulo $9$).
    \item[MISD] (Multiple Instruction Single Data). Esta combinación nunca se ha llevado a la práctica. Se incluye solamente
    por completitud. No es de extrañar: se correspondería con un sistema que para el procesamiento de un sólo dato requeriría
    la utilización simultánea de múltiples instrucciones.
    \item[SIMD] (Single Instruction Multiple Data). Una única secuencia de intrucciones es remitida a cada una de las unidades
    de encargadas del procesamiento de cada una de las múltiples secuencias de datos. Esto se ilustra esquemáticamente en la figura
    \ref{fig:conSIMD} de la sección \label{basico:cpusimd}, que se reproduce de nuevo en la figura \ref{fig:conSIMDBIS} por comodidad.
    \begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth,keepaspectratio]{conSIMD} 
    \caption{Utilizando SIMD}\label{fig:conSIMDBIS}
    \end{figure}

    \item[MIMD] (Multiple Instruction Multiple Data). Cada unidad procesa su propia secuencia de instrucciones sobre sus propios datos. 
    Es la arquitectura más general, ya que cualquiera de los otros tres casos se contiene en este. En la siguiente sección \ref{sec:mimd}
    se pormenoriza esta categoría. Un esquema de esta arquitectura se muestra en la figura \ref{fig:mimd}.
    \end{description}

    \begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth,keepaspectratio]{mimd} 
    \caption{Utilizando MIMD}\label{fig:mimd}
    \end{figure}


    \subsubsection{MIMD}\label{sec:mimd}
    La descripción que se deriva de simplemente las siglas de esta categoría es en exceso superficial. Dentro de esta arquitectura 
    se distinguen dos enfoques fundamentales basados en la organización de la memoria. 

    \paragraph{Memoria compartida}
    La organización de estos sistemas se muestra en la figura \ref{fig:sharedmem}: cada unidad de procesamiento 
    \emph{comparte} una memoria global, con la cual se comunican mediante un único bus. Las unidades de procesamiento
    pueden compartir asimismo una memoria caché o bien poseer cachés independientes. Este último caso se corresponde
    con el concepto de \emph{symmetric multiprocessor} (SMP). Hasta fechas recientes, esta era la forma habitual en la que
    entendían los sistemas de memoria compartida: una placa con varios procesadores \emph{independientes} e \emph{identicos}.
    Con la llegada de los procesadores \emph{multinúcleo}, el panorama se diversifica: en la arquitectura Core de Intel,
    cada núcleo --unidad de procesamiento-- cuenta con su propia caché L1, mientras que la caché L2 y la L3 
    --en los casos en los que ésta se encuentra
    presente-- se comparte\footnote{vease \cite{sharedcacheintel} para una muy interesante discusión de las ventajas de
    este enfoque}. Por otra parte, la última microarquitectura de AMD en el momento de escribir estas líneas\footnote{finales de $2007$}
    , AMD K10, no comparte ninguno de los niveles de caché
    entre núcleos. La comparativa y valoración de las ventajas e inconvenientes de uno y otro enfoque están fuera del 
    alcance de esta memoria.

    \begin{figure}[h]
    \centering
    \includegraphics[width=0.45\textwidth,keepaspectratio]{sharedmemory} 
    \caption{Memoria compartida}\label{fig:sharedmem}
    \end{figure}

    En un sistema de memoria compartida, cualquier unidad de procesamiento tiene acceso al contenido de cualquier posición
    de memoria mediante las operaciones de carga habituales. Esto facilita la comunicación entre las diferentes unidades de
    ejecución (hilos), pero requiere de mecanismos de sincronización para evitar situaciones en las cuales más de uno
    de estos hilos accede con intención de escribir a una estructura compartida. Una visión general de estos mecanismos se da
   en  \cite{sourcebook}\footnote{sección 2.2.1, pág. 30}. 

    La principal limitación de los sistemas de memoria compartida es su escalabilidad: cuando el número de elementos
    que comparten el bus que lo comunican con la memoria compartida es elevado ($\approx 32$ hablando en términos prácticos
    a día de hoy, \cite{sourcebook}), el fenómeno de contención en el bus termina por echar por tierra cualquier ganancia
    derivada del aumento del número de unidades de procesamiento.

    En lo referente a la biblioteca, este es el paradigma utilizando siempre que se habla de paralelismo.

    \paragraph{Memoria distribuida}
    La característica de estos sistemas es que cada proceso posee su propio espacio de direcciones y se comunica con otros procesos
    a través del \emph{paso de mensajes}. Cada unidad de procesamiento posee su propia memoria local, véase la figura \ref{fig:distmem}. 
    \begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth,keepaspectratio]{distributedmemory} 
    \caption{Memoria distribuida}\label{fig:distmem}
    \end{figure}
    Resultan ser mucho más escalables que los sistemas de memoria compartida si la estratégia de interconexión es adecuada\footnote{
      \cite{sourcebook} apunta como una red en hipercubo tiene un coste proporcional a $n \lg{(n)}$, con $n$ el número de unidades
        de procesamiento.}. 

    El problema que se presenta con estos sistemas es de comunicación: dado que la latencia en el envio de mensajes es mucho mayor
    que la de procesamiento, resulta vital una correcta una subdivisión del problema en porciones suficientemente grandes, a fin 
    de compensar el coste de la comunicación. 

    Pese a que en el presente proyecto no se utilizan tecnologías tales como MPI\footnote{\url{http://www-unix.mcs.anl.gov/mpi/}} 
    para la implementación de los métodos en sí, se puede enmarcar la aplicación MPPLab --descrita en el capítulo \ref{chap:mpplab}--
    dentro de este paradigma.

    \bigskip

    Además de estos dos enfoques, existen diversas soluciones intermedias, en las cuales no se va a profundizar aquí. Vease
    \cite{parpatterns, sourcebook}\footnote{pág 12; sección 3.1, pág. 45 resp.}.


\section{Potenciación modular}
  \subsection{Dos hilos y $\mathbb{Z}M_n$}
  \cite{modexpmont}
  \subsection{Mi método}

\section{Vectores}
  \subsection{Dot product} %FIXME

\section{Matrices}
  \subsection{Producto}
  \subsection{Descomposición $LU$}
  \subsection{Inversión}
  \subsection{Transposición}
  \subsection{Determinante}
    \subsubsection{Algoritmo de Gauss-Bareiss}\label{para:bareiss}
    Descrito en la sección \ref{impl:bareiss}. Si se representa el patrón de accesos derivado 
    de su algoritmo secuencial (algoritmo \ref{alg:bareiss}), no es difícil derivar una división
    en tareas basada en la secuencia de patrones de diseño 
    (data decomposition/order tasks -> geom. decomposition -> loop paralelism)
    de \cite{parpatterns}. En la figura \ref{fig:accBar} 
    se muestra el patrón de accesos para el algoritmo.  Los elementos de color verde
    indican accesos de \emph{lectura}, mientras que los de color rojo indican también \emph{escritura}.

   \begin{figure}[h]
    \centering
    \includegraphics[width=0.95\textwidth,keepaspectratio]{patronAccesosBarreis} 
    \caption{Patrón accesos Gauss-Bareiss}\label{fig:accBar}
  \end{figure}



  \subsection{Operaciones de caracter vectorial}
    % sumas, restas, prod por escalares

\section{Cálculo de \textit{reducciones}}


\section{Polinomios}
  \subsection{Producto}
  \subsection{Operaciones de caracter vectorial}
    % sumas, restas, prod por escalares
  \subsection{Evaluación}\label{parallel:evalPoly}
    \cite{dorn}


