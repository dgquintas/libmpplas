This file was created with JabRef 2.2.
Encoding: UTF-8

@BOOK{intelOpt,
  title = {IA-32 Intel Architecture Optimization Reference Manual},
  publisher = {Inter Corp.},
  year = {2006},
  author = {Intel Corp.},
  month = {April},
  owner = {dgquintas},
  timestamp = {2007.02.18},
  url = {http://www.intel.com/products/processor/manuals/index.htm}
}

@BOOK{intelVol1,
  title = {IA-32 Intel Architecture Software Developer's Manual},
  publisher = {Inter Corp.},
  year = {2006},
  author = {Intel Corp.},
  month = {April},
  owner = {dgquintas},
  pdf = {http://www.intel.com/design/processor/manuals/253665.pdf},
  timestamp = {2007.02.18},
  url = {http://www.intel.com/products/processor/manuals/index.htm}
}

@ARTICLE{dorn,
  author = {W.S. Dorn},
  title = {Generalizations of Horner's Rule for Polynomial Evaluation},
  journal = {IBM Journal},
  year = {1962},
  pages = {239-245},
  owner = {dgquintas},
  timestamp = {2007.10.22}
}

@BOOK{foster,
  title = {Designing and Building Parallel Programs},
  publisher = {Addison-Wesley},
  year = {1995},
  author = {Ian Foster},
  owner = {dgquinta},
  timestamp = {2007.03.08},
  url = {http://www-unix.mcs.anl.gov/dbpp/}
}

@INPROCEEDINGS{karatsubaPar,
  author = {Tudor Jebelean},
  title = {Using the Parallel Karatsuba Algorithm for Long Integer Multiplication
	and Division},
  booktitle = {European Conference on Parallel Processing},
  year = {1997},
  pages = {1169-1172},
  url = {citeseer.ist.psu.edu/189168.html}
}

@TECHREPORT{landscape,
  author = {Krste Asanovic, Ras Bodik, Bryan Christopher Catanzaro, Joseph James
	Gebis, Parry Husbands, Kurt Keutzer, David A. Patterson, William
	Lester Plishker, John Shalf, Samuel Webb Williams and Katherine A.
	Yelick},
  title = {The Landscape of Parallel Computing Research: A View from Berkeley},
  institution = {EECS Department, University of California, Berkeley},
  year = {2006},
  number = {UCB/EECS-2006-183},
  month = {December 18},
  abstract = {The recent switch to parallel microprocessors is a milestone in the
	history of computing. Industry has laid out a roadmap for multicore
	designs that preserves the programming paradigm of the past via binary
	compatibility and cache coherence. Conventional wisdom is now to
	double the number of cores on a chip with each silicon generation.
	
	
	A multidisciplinary group of Berkeley researchers met nearly two years
	to discuss this change. Our view is that this evolutionary approach
	to parallel hardware and software may work from 2 or 8 processor
	systems, but is likely to face diminishing returns as 16 and 32 processor
	systems are realized, just as returns fell with greater instruction-level
	parallelism.
	
	
	We believe that much can be learned by examining the success of parallelism
	at the extremes of the computing spectrum, namely embedded computing
	and high performance computing. This led us to frame the parallel
	landscape with seven questions, and to recommend the following: •
	The overarching goal should be to make it easy to write programs
	that execute efficiently on highly parallel computing systems • The
	target should be 1000s of cores per chip, as these chips are built
	from processing elements that are the most efficient in MIPS (Million
	Instructions per Second) per watt, MIPS per area of silicon, and
	MIPS per development dollar. • Instead of traditional benchmarks,
	use 13 "Dwarfs" to design and evaluate parallel programming models
	and architectures. (A dwarf is an algorithmic method that captures
	a pattern of computation and communication.) • "Autotuners" should
	play a larger role than conventional compilers in translating parallel
	programs. • To maximize programmer productivity, future programming
	models must be more human-centric than the conventional focus on
	hardware or applications. • To be successful, programming models
	should be independent of the number of processors. • To maximize
	application efficiency, programming models should support a wide
	range of data types and successful models of parallelism: task-level
	parallelism, word-level parallelism, and bit-level parallelism. •
	Architects should not include features that significantly affect
	performance or energy if programmers cannot accurately measure their
	impact via performance counters and energy counters. • Traditional
	operating systems will be deconstructed and operating system functionality
	will be orchestrated using libraries and virtual machines. • To explore
	the design space rapidly, use system emulators based on Field Programmable
	Gate Arrays (FPGAs) that are highly scalable and low cost.
	
	
	Since real world applications are naturally parallel and hardware
	is naturally parallel, what we need is a programming model, system
	software, and a supporting architecture that are naturally parallel.
	Researchers have the rare opportunity to re-invent these cornerstones
	of computing, provided they simplify the efficient programming of
	highly parallel systems.},
  url = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2006/EECS-2006-183.html}
}

@ARTICLE{openmpMSDN,
  author = {Pete Isensee, Kang Su Gatlin},
  title = {OpenMP and C++: Reap the Benefits of Multithreading without All the
	Work},
  journal = {MSDN Magazine},
  year = {2005},
  month = {October},
  owner = {dgquintas},
  timestamp = {2007.02.18},
  url = {http://msdn.microsoft.com/msdnmag/issues/05/10/OpenMP/default.aspx}
}

@BOOK{parpatterns,
  title = {Patterns for Parallel Programming},
  publisher = {Addison-Wesley},
  year = {2004},
  editor = {John M. Vlissides},
  author = {Timothy G. Mattson, Beverly A. Sanders, Berna L. Massingill},
  series = {Software Patterns Series},
  edition = {1},
  month = {December},
  owner = {dgquinta},
  timestamp = {2007.02.15}
}

@BOOK{aix,
  title = {AIX Version 4.3 General Programming Concepts: Writing and Debugging
	Programs},
  year = {1999},
  pages = {Chapter 9},
  edition = {2},
  month = {September},
  owner = {dgquinta},
  timestamp = {2007.03.08},
  url = {http://www.unet.univie.ac.at/aix/aixprggd/genprogc/toc.htm}
}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: selector_author:}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_keywords:}

